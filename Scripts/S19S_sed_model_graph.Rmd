---
title: "WHONDRS_S19S_analysis"
author: "Jianqiu Zheng"
date: "3/14/2024"
output: html_document
---

```{r setup, include=FALSE}
#Load the required packages
library(tidyverse)
library(dplyr)
library(reshape)
library(ggplot2)
library(ggpubr)
library(scales)
library(ggpmisc)
theme_pubclean()
```

## Pull sediment metadata and create sample map
```{r metadata}
#Load WHONDRS S19S data (presence/absence)
geodata <- read.csv('v4_WHONDRS_S19S_Metadata.csv')
geosub<- geodata[geodata$Country=="USA", ]


df_geo<-geosub[c("Sample_ID", "Stream_Order","MS_Latitude_dec.deg","MS_Longitude_dec.deg")]
colnames(df_geo)<-c("ID","Stream_order","Latitude", "Longitude")
df_geo[df_geo == "Not_Provided"] <- NA


library(sf)
library(rnaturalearth)

# convert your data frame to an sf object
pts_sf <- st_as_sf(df_geo, coords = c("Longitude", "Latitude"), crs = 4326)  # WGS 84

# U.S. state polygons
us_states <- ne_states(country = "United States of America", returnclass = "sf")

# split into CONUS (lower-48) and Alaska
conus  <- us_states[!us_states$name %in% c("Alaska", "Hawaii",
                                           "Puerto Rico", "Guam",
                                           "Northern Mariana Islands",
                                           "American Samoa"), ]
alaska <- us_states[us_states$name == "Alaska", ]

## 1.  Dissolve state polygons into single CONUS & Alaska shells ----
conus_union  <- st_union(conus)     # 1 multipolygon
alaska_union <- st_union(alaska)    # 1 multipolygon

## 2.  Logical vector (length = nrow(pts_sf)) for each region --------
in_conus  <- st_within(pts_sf, conus_union,  sparse = FALSE)[, 1]
in_alaska <- st_within(pts_sf, alaska_union, sparse = FALSE)[, 1]

## 3.  Subset ---------------------------------------------------------
pts_conus <- pts_sf[in_conus, ]
pts_ak    <- pts_sf[in_alaska, ]


plot1<- ggplot() +
  geom_sf(data = conus, fill = "grey95", colour = "grey60", linewidth = 0.15) +
  geom_sf(data = pts_conus, aes(fill = Stream_order), shape = 21, size = 3, colour = "black") +
    coord_sf(expand = FALSE) +
  scale_fill_brewer(palette = "Set3") +
 theme_minimal(base_size = 11, base_family = "Helvetica") %+replace%
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background  = element_rect(fill = "white", colour = NA), legend.position="top")+
  labs( fill = "Stream Order")



  p_ak <- ggplot() +
  geom_sf(data = alaska, fill = "grey95", colour = "grey60", linewidth = 0.15) +
  geom_sf(data = pts_ak,
          aes(fill = Stream_order), shape = 21, size = 3, stroke = 0.4, colour = "black") +
  coord_sf(xlim = c(-170, -130), ylim = c(50, 72), expand = FALSE, datum = NA) +
  scale_fill_brewer(palette = "Set3", guide = "none") +        # hide legend
  theme_void()  
  
library(patchwork)

p_final <- plot1 +
  inset_element(p_ak,
                left   = 0.02,  # NPC units (0-1) from left edge of main panel
                bottom = 0.73,  # NPC units from bottom edge
                right  = 0.27,  # width 30 % of main panel
                top    = 0.98,  # height 30 %
                clip   = TRUE,  # clip anything that spills outside box
                align_to = "full")  # keeps coordinates in npc space

p_final


pdf("site_map_all.pdf", width=5.5, height=5.5)
p_final
dev.off() 

```


## creating a lookup table with mass
## Mass,MolForm, ID, Position
```{r metadata}
#Load WHONDRS S19S data (presence/absence)
data <- read.csv('Processed_Clean_S19S_Water_Field_sediments_9-29_Data.csv')

#Load WHONDRS S19S molarity data 
mol <- read.csv('Processed_Clean_S19S_Water_Field_sediments_9-29_Mol.csv')

#Change column header 
names(data)[1] <- "Mass"

#Create ID column
data <- mutate(data, ID = row_number())
mol <- mutate(mol, ID = row_number())

#Subset mol to get df of just Mass and MolForm
mol_subset <- mol %>% select(ID, Mass, MolForm)

#Merge data and mol
df <- merge(data, mol_subset, by= "ID")

#Select wanted columns and remove NAs and 0 counts
df_subset <- df %>% 
              select(-one_of('ID', 'Mass.y')) %>% 
              select('Mass.x', 'MolForm', everything()) %>% 
              pivot_longer(!c(Mass.x, MolForm), names_to = "Site_ID", 
                           values_to = "Count") %>%
              filter(Count != 0)%>%
              na.omit()



#Extract the sample type (water or sediment)
df_subset$Type <- ifelse(grepl("Sed", df_subset$Site_ID), "Sediment", "Water")

sed_df <- filter(df_subset, Type == "Sediment")
water_df <- filter(df_subset, Type == "Water")

#Write df to csv file
write.csv(sed_df,file = "S19S_sed_with_metadata.csv")
# write.csv(water_df,file = "S19S_water_with_metadata.csv")

```


##Match thermodynamic modeling results with samples using the lookup table
```{r cars}
#test read csv file to make sure ID is character
meta<- read.csv("S19S_sed_with_metadata.csv") 
meta$Position<-sub(".*_ICR\\.([A-Za-z]).*", "\\1", meta$Site_ID)
meta$ID<-sub(".*S19S_([0-9]{4})_Sed.*", "\\1", meta$Site_ID)


##load modeling results
ther<- read.csv("S19S_sed_oxy.csv")


#Select wanted columns 
ther_subset <- ther %>% 
              select('delGcat','lambda','ne','stoichMet_donor','stoichMet_acceptor','stoichMet_hco3','C_num','CUE')

#Select wanted columns 
meta_subset <- meta %>% 
              select('ID','Position','MolForm')

##match ID, peaks and predictions
ther_meta<- cbind(meta_subset,ther_subset)

unique(ther_meta$ID)

write.csv(ther_meta,file = "S19S_sed_therm_meta.csv")

```


#visualize data distribution 

```{r mean}
ther_data<-read.csv("S19S_sed_therm_meta.csv", colClasses = c(ID = "character"))

#density distribution plot
plot1<-ggplot(data=ther_data, aes(x=CUE))+ 
  #geom_histogram(aes(y=..density..,color=Amendment, fill=Amendment),binwidth=40,alpha=0.2, position="identity")+ 
  geom_density(aes(color=ID), size=1)+
  scale_x_continuous(limits=c(0,1))+
  #scale_y_continuous(limits=c(0, 2e-4),breaks=seq(0,2e-4, by=1e-4))+
  #scale_fill_manual(values = c("#E7B800","#0073C2FF", "#FC4E07","#00AFBB")) +
  #scale_color_manual(values = c("#E7B800","#0073C2FF", "#FC4E07","#00AFBB"))+
  #theme_pubr(border=TRUE)+theme(legend.position=c(0.12,0.75))+  theme(panel.grid.minor.x=element_line(linetype="dashed", color="gray",size=0.2))+
  theme(panel.grid.major.x=element_line(linetype="dashed", color="gray",size=0.2))
## blue, red, yellow:  "#0073C2FF", "#FC4E07","#E7B800"
plot1

```


#Seperating data by ID and position (creating indivisual files, useful or not??)

```{r sep}
#Select upstream sediment samples 
up.data = subset(ther_data, Position=="U")

mid.data = subset(ther_data, Position=="M")
low.data = subset(ther_data, Position=="D")
up.data<-up.data[,-1]
mid.data<-mid.data[,-1]
low.data<-low.data[,-1]

#Select for variables of interest---up
var_study <- unique (up.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(up.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_up.csv"),row.names = FALSE)
}

#Select for variables of interest--mid
var_study <- unique (mid.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(mid.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_mid.csv"),row.names = FALSE)
}


#Select for variables of interest---down
var_study <- unique (low.data$ID) %>% sort() #unique study names
length(var_study)
#For each site subset, eliminate rows with 0 and format headers
for (i in 1:length(var_study)) {
   sub_study <- subset(low.data, ID == var_study[i])
  write.csv(sub_study,file=paste0(i,"_low.csv"),row.names = FALSE)
}

```
#####-----------------------------------------------------------------------------------------

#Extract all miscellaneous data: rates, npoc, cell counts, grain size
```{r cars}
###using ESS-DIVE dataset v6 ()

#Take sediment wet mass, replace missing values with mean
mass<-read.csv("WHONDRS_S19S_Sediment_Water_Mass_Volume.csv")
mass <- mass %>% select(Sample_ID, Wet_Sediment_Mass_g, Water_Mass_g) #10mL sediment used for incubation
mass[mass==-9999]<-NA
mean<-mean(mass$Wet_Sediment_Mass_g, na.rm=TRUE) ##18.61574
mass[is.na(mass)]<- mean
colnames(mass)<-c("ID","sed_mass","water_mass")

rates<- read.csv("WHONDRS_S19S_Sediment_Incubations_respiration_Rates_v6.csv")
rates<- rates %>% select(Sample_ID,rate_mg_per_L_per_h )
colnames(rates)<-c('ID', 'rate')#mg_DO_per_H_per_L_sediment

raw_npoc<- read.csv("WHONDRS_S19S_Sediment_NPOC.csv") #NPOC_mg_per_L_as_C
colnames(raw_npoc)<-c('study','ID', 'conc')
npoc<-raw_npoc%>% select(ID, conc)
npoc$conc[npoc$conc=="Above_Range_Greater_Than_22"]<-NA


raw_fc<- read.csv("WHONDRS_S19S_Sediment_FlowCytometry.csv")
colnames(raw_fc)<-c('study','ID', 'bac', 'photo', 'hetero')
##testing correlations
test1<-cor(raw_fc$bac,raw_fc$hetero, method='pearson')  ##0.9999
test2<-cor(raw_fc$photo,raw_fc$hetero, method='pearson') ##0.8025
##log10 transfer 
raw_fc$biomass<-log10(raw_fc$hetero)
fc<-raw_fc%>% select(ID, biomass)

raw_gs<- read.csv("WHONDRS_S19S_Sediment_GrainSize.csv")
colnames(raw_gs)<-c('study','ID', 'fine','med','coarse','sand','clay','silt')
##testing correlations
test1<-cor(raw_gs$fine,raw_gs$sand, method='pearson')  ##0.053
test2<-cor(raw_gs$med,raw_gs$sand, method='pearson')  ##0.999
test3<-cor(raw_gs$coarse,raw_gs$sand, method='pearson')  ##-0.09
test4<-cor(raw_gs$clay,raw_gs$sand, method='pearson')  ##0.0005
test5<-cor(raw_gs$silt,raw_gs$sand, method='pearson')  ##0.998

## run a simple/ideal surface area calculation
raw_gs<-subset(raw_gs, select=-c(study,sand))
test_gs<-head(raw_gs, 30)
  
test_gs1<-reshape2::melt(test_gs, id.var="ID")

  
###visualize grainsize distribution by weight
plot1<-ggplot(test_gs1, aes(x=ID, y=value, fill=variable))+geom_bar(position="stack",stat="identity")+
scale_fill_manual(values=c("#8073ac","#b2abd2","#d8daeb","#fdb863","#b35806"))+
  theme_linedraw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+theme(text = element_text(size=16))+theme(axis.text.x=element_text(angle=90, vjust=0.5,hjust=1))

pdf("example grain size.pdf", width=8, height=5)
plot1
dev.off() 
################
  
###visualize grainsize distribution by volume
##calculations
vgs<-data.frame(ID=raw_gs$ID)

raw_gs$v_f<-raw_gs$fine/1.60
raw_gs$v_m<-raw_gs$med/1.70
raw_gs$v_c<-raw_gs$coarse/1.70
raw_gs$v_clay<-raw_gs$clay/1.40
raw_gs$v_silt<-raw_gs$silt/1.55
raw_gs$sum<-raw_gs$v_f+raw_gs$v_m+raw_gs$v_c+raw_gs$v_clay+raw_gs$v_silt

vgs$fine<-raw_gs$v_f/raw_gs$sum
vgs$med<-raw_gs$v_m/raw_gs$sum
vgs$coarse<-raw_gs$v_c/raw_gs$sum
vgs$clay<-raw_gs$v_clay/raw_gs$sum
vgs$silt<-raw_gs$v_silt/raw_gs$sum


test_vgs<-head(vgs, 30)
  
test_vgs1<-reshape2::melt(test_vgs, id.var="ID")

plot1<-ggplot(test_vgs1, aes(x=ID, y=value, fill=variable))+geom_bar(position="stack",stat="identity")+
scale_fill_manual(values=c("#8073ac","#b2abd2","#d8daeb","#fdb863","#b35806"))+
  theme_linedraw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+theme(text = element_text(size=16))+theme(axis.text.x=element_text(angle=90, vjust=0.5,hjust=1))

pdf("example grain size by v.pdf", width=10, height=5)
plot1
dev.off() 


raw_gs$ssa_mean<-6*(raw_gs$fine*0.178^2+raw_gs$med*0.375^2+raw_gs$coarse*1.25^2+raw_gs$clay*0.002^2+raw_gs$silt*0.0275^2)

raw_gs$ssa_tot<-raw_gs$fine/0.178/1.6+raw_gs$med/0.375/1.7+raw_gs$coarse/1.25/1.8+raw_gs$clay/0.002/1.4+raw_gs$silt/0.0275/1.55  ###

gs<-raw_gs
```



# Merge all bulk sediment data with FTICR data based on location and site ID
```{r plotting}
#Select samples byID
##Dropping non US sites
ids_drop <- c("0001","0003","0004","0005","0045","0046","0056","0059","0092","0093","0096") 

#----------rate---------------------
up_rates <- rates[grep("SED_INC-U",rates$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(up_rates)<-c('ID', 'rate')
unique(up_rates$ID)
up_rates$site = str_extract(up_rates$ID, "[0-9]{4}")
up_rates<-up_rates[,-1]
up_rates<-up_rates[!up_rates$site %in% ids_drop , ]

#----------npoc---------------------
up_npoc<- npoc[grep("Sed_Field_ICR-U",npoc$ID), ] 
up_npoc$site = str_extract(up_npoc$ID, "[0-9]{4}")
up_npoc<-up_npoc[,-1] 
up_npoc<-up_npoc[!up_npoc$site %in% ids_drop , ]

#----------biomass---------------------
up_biomass<- fc[grep("FCS-U",fc$ID), ] 
up_biomass$site = str_extract(up_biomass$ID, "[0-9]{4}")
up_biomass<-up_biomass[,-1] 
up_biomass<-up_biomass[!up_biomass$site %in% ids_drop , ]

#----------sediment/water mass---------------------
up_mass<- mass[grep("SED_INC-U",mass$ID), ] 
up_mass$site = str_extract(up_mass$ID, "[0-9]{4}")
up_mass<-up_mass[,-1] 
up_mass<-up_mass[!up_mass$site %in% ids_drop , ]

#----------grainsize---------------------
up_gs<- gs[grep("BULK-U",gs$ID), ] 
up_gs$site = str_extract(up_gs$ID, "[0-9]{4}")
up_gs<-up_gs[,-1] 
up_gs<-up_gs[!up_gs$site %in% ids_drop , ]

#merge all miscellaneous data--------------------
up_list<-list(up_rates, up_npoc, up_biomass,up_mass, up_gs)

##counting observations for each column without NA
id_cols<-c("site")
up_count <- lapply(
  up_list,
  function(x) {
    x <- x[ , !(names(x) %in% id_cols), drop = FALSE]   # ← remove ID columns
    colSums(!is.na(x))                                  # count the rest
  }
)
up_dfs <- map(up_count, ~ as.data.frame(t(.x)))
up_summary <- up_dfs %>% 
  bind_rows() %>%                            # 5 rows, padded with NA
  summarise(across(everything(), sum, na.rm = TRUE))  # ⇢ 1 row, totals

#---
up<- up_list %>% reduce(full_join, by='site')
up<-select(up, "site","rate","conc","biomass","sed_mass","water_mass","clay","silt","fine","med","coarse","ssa_mean","ssa_tot")

###merge with thermodynamic modeling results
colnames(up.data)[1]<-"site"

#Merge data by site number--modeling results and measured concentration and rates
testtt<-merge (up.data, up,by='site') 
write.csv(testtt,'up_all.csv', row.names = FALSE)

#--------------------
#Select samples
mid_obv <- rates[grep("SED_INC-M",rates$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(mid_obv)<-c('ID', 'rate')
unique(mid_obv$ID)
mid_obv$site = str_extract(mid_obv$ID, "[0-9]{4}")
mid_obv<-mid_obv[,-1]
mid_obv<-mid_obv[!mid_obv$site %in% ids_drop , ]

mid_npoc<- npoc[grep("Sed_Field_ICR-M",npoc$ID), ] 
mid_npoc$site = str_extract(mid_npoc$ID, "[0-9]{4}")
mid_npoc<-mid_npoc[,-1] 
mid_npoc<-mid_npoc[!mid_npoc$site %in% ids_drop , ]

#----------biomass---------------------
mid_biomass<- fc[grep("FCS-M",fc$ID), ] 
mid_biomass$site = str_extract(mid_biomass$ID, "[0-9]{4}")
mid_biomass<-mid_biomass[,-1] 
mid_biomass<-mid_biomass[!mid_biomass$site %in% ids_drop , ]

#----------sediment mass---------------------
mid_mass<- mass[grep("SED_INC-M",mass$ID), ] 
mid_mass$site = str_extract(mid_mass$ID, "[0-9]{4}")
mid_mass<-mid_mass[,-1] 
mid_mass<-mid_mass[!mid_mass$site %in% ids_drop , ]

#----------grainsize---------------------
mid_gs<- gs[grep("BULK-M",gs$ID), ] 
mid_gs$site = str_extract(mid_gs$ID, "[0-9]{4}")
mid_gs<-mid_gs[,-1] 
mid_gs<-mid_gs[!mid_gs$site %in% ids_drop , ]

#merge all miscellaneous data--------------------
mid_list<-list(mid_obv, mid_npoc, mid_biomass, mid_mass,mid_gs)
##counting
mid_count <- lapply(
  mid_list,
  function(x) {
    x <- x[ , !(names(x) %in% id_cols), drop = FALSE]   # ← remove ID columns
    colSums(!is.na(x))                                  # count the rest
  }
)
mid_dfs <- map(mid_count, ~ as.data.frame(t(.x)))
mid_summary <- mid_dfs %>% 
  bind_rows() %>%                            # 5 rows, padded with NA
  summarise(across(everything(), sum, na.rm = TRUE))  # ⇢ 1 row, totals
#---

mid<- mid_list %>% reduce(full_join, by='site')
mid<-select(mid, "site","rate","conc","biomass","sed_mass","water_mass","clay","silt","fine","med","coarse","ssa_mean","ssa_tot")

mid[mid==-9999]<-NA

## merge with thermodynamic parameters
colnames(mid.data)[1]<-"site"

#Merge data by site number--modeling results and measured concentration and rates
mid_all<-merge (mid.data, mid,by='site') 
write.csv(mid_all,'mid_all.csv', row.names = FALSE)


#--------------------
#Select samples
low_obv <- rates[grep("SED_INC-D",rates$ID), ] ##grep--globally search for a regular expression and print matching lines---return lines
colnames(low_obv)<-c('ID', 'rate')
unique(low_obv$ID)
low_obv$site = str_extract(low_obv$ID, "[0-9]{4}")
low_obv<-low_obv[,-1]
low_obv<-low_obv[!low_obv$site %in% ids_drop , ]

low_npoc<- npoc[grep("Sed_Field_ICR-D",npoc$ID), ] 
low_npoc$site = str_extract(low_npoc$ID, "[0-9]{4}")
low_npoc<-low_npoc[,-1] 
low_npoc<-low_npoc[!low_npoc$site %in% ids_drop , ]


#----------biomass---------------------
low_biomass<- fc[grep("FCS-D",fc$ID), ] 
low_biomass$site = str_extract(low_biomass$ID, "[0-9]{4}")
low_biomass<-low_biomass[,-1] 
low_biomass<-low_biomass[!low_biomass$site %in% ids_drop , ]
#----------sediment mass---------------------
low_mass<- mass[grep("SED_INC-D",mass$ID), ] 
low_mass$site = str_extract(low_mass$ID, "[0-9]{4}")
low_mass<-low_mass[,-1] 
low_mass<-low_mass[!low_mass$site %in% ids_drop , ]
#----------grainsize---------------------
low_gs<- gs[grep("BULK-D",gs$ID), ] 
low_gs$site = str_extract(low_gs$ID, "[0-9]{4}")
low_gs<-low_gs[,-1] 
low_gs<-low_gs[!low_gs$site %in% ids_drop , ]

#merge all miscellaneous data--------------------
low_list<-list(low_obv, low_npoc, low_biomass,low_mass, low_gs)

##counting
low_count <- lapply(
  low_list,
  function(x) {
    x <- x[ , !(names(x) %in% id_cols), drop = FALSE]   # ← remove ID columns
    colSums(!is.na(x))                                  # count the rest
  }
)
low_dfs <- map(low_count, ~ as.data.frame(t(.x)))
low_summary <- low_dfs %>% 
  bind_rows() %>%                            # 5 rows, padded with NA
  summarise(across(everything(), sum, na.rm = TRUE))  # ⇢ 1 row, totals

#--
low<- low_list %>% reduce(full_join, by='site')
low<-select(low, "site","rate","conc","biomass","sed_mass","water_mass","clay","silt","fine","med","coarse","ssa_mean","ssa_tot")


#Merge data by site number--modeling results and measured concentration and rates
colnames(low.data)[1]<-"site"
low_all<-merge (low.data, low,by='site') 
write.csv(low_all,'low_all.csv', row.names = FALSE)


###---
up_summary$loc<-c("up")
mid_summary$loc<-c("mid")
low_summary$loc<-c("low")
counts_summary<-rbind(up_summary, mid_summary, low_summary)
final<-select(counts_summary, "loc", "rate","conc","biomass","fine")
colnames(final)<-c("Location","Rate","NPOC","Biomass","Grain_size")
write.csv(final,'counts_summary.csv', row.names = FALSE)

```

##create data summary plots
```{r bargraphs}
counts<-read.csv("counts_summary.csv")

##add fticr counts
length(unique(up.data$site)) #80
length(unique(mid.data$site)) #83
length(unique(low.data$site)) #76

counts$FTICR_MS<-c(80,83,76)
df<-melt(counts, id.var=c("Location"))

test<-ggplot(df, aes(x=value, y=variable, fill=variable))+geom_col(width =0.7, show.legend=FALSE)+
               facet_wrap(~Location, ncol=1, labeller = as_labeller(c(up  = "Upstream",mid = "Midstream",
      low = "Downstream")))+ labs(x="Number of sites", y=NULL)+
  scale_fill_brewer(palette = "Set2") +theme_minimal(base_size = 12) +
  theme(
    strip.text = element_text(face = "bold"),  # facet labels
    panel.grid.major.y = element_blank()       # drop y-gridlines if desired
  )

pdf("site_data.pdf", width=3.5, height=5.5)
test
dev.off() 

```


##Sediment data summary and basic correlations (data point per site)
```{r basic correlation analysis}
##load processed data, each row represents one sample with all thermodynamic parameters estimated as the mean (need to work on this!!!!)


up<- read.csv("up_all.csv",colClasses=c("site"="character"))
mid<- read.csv("mid_all.csv",colClasses=c("site"="character"))
low<- read.csv("low_all.csv",colClasses=c("site"="character"))


##creating correlation matrix plot-----------
alldata<-rbind(up, mid, low)
new<-as.data.frame(na.omit(alldata))
#new$NPOC<-as.numeric(as.character(new$NPOC))
###fixing units both rate and concentration are in mg g-1
new$resp<-new$rate*(new$water_mass+10)*0.01/new$sed_mass
new$npoc<-new$conc*(new$water_mass+10)*0.01/new$sed_mass
new$respC<-new$resp/32*12 ##convert mgDO g-1 to mgC g-1
new$xlab<-1/new$npoc
newdata<-select(new,"CUE","ne","delGcat","lambda","respC","npoc","biomass","clay","silt","fine","med","coarse","ssa_mean","ssa_tot")


#data visualization respiration-1/NPOC
plot1<-ggplot(data=new, aes(x=xlab, y=respC))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#8073ac")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+ ylim(c(0,0.6))+
  stat_poly_line(color="black") +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+
  xlab(bquote('lambda'))+ylab(bquote('Respiration rate ('*mgC~h^-1~g^-1*')'))
plot1

pdf("lambda_rate_corr.pdf", width=3.8, height=3.5)
plot1
dev.off() 


```


## ##############################################################################################
##Testing the binning approach from Stegen paper, reproduce the constrain curve
```{r binning}
########Defining the segments
ideal.num.segments = 10

#######Number of peaks normalized by NPOC
dataset<-as.data.frame(na.omit(new))
field.step = (max(dataset$xlab)- min(dataset$xlab))/(ideal.num.segments)
  
  peak.segments = as.data.frame(matrix(NA,ncol = 4,nrow = ideal.num.segments))
  colnames(peak.segments)= c("Low.boundary","High.boundary","Max.resp","Mid.peaks")
  
  temp.low = min(dataset$xlab)
  
  for (i in 1:ideal.num.segments){
    
    if (i == 10){
      
      temp.high = temp.low + field.step
      temp.high = plyr::round_any(temp.high, 0.0001, f = ceiling)
      temp.dat = dataset[which(dataset$xlab >= temp.low & dataset$xlab <= temp.high),]
      
    }else{
    temp.high = temp.low + field.step
    temp.dat = dataset[which(dataset$xlab >= temp.low & dataset$xlab <= temp.high),]
    }
    
    if (nrow(temp.dat) > 0){
      temp.rate = max(dataset$respC[which(dataset$xlab >= temp.low & dataset$xlab <= temp.high)])
      
    
      temp.mid =  dataset$xlab[which(dataset$respC %in% temp.rate)]
      
      peak.segments$Low.boundary[i] = temp.low 
      peak.segments$High.boundary[i] = temp.high
      peak.segments$Max.resp[i] = temp.rate
      peak.segments$Mid.peaks[i] = temp.mid
      
      temp.low = temp.high  
      
    } else if (nrow(temp.dat) == 0){
      temp.rate = NA
      
  
      temp.mid =  NA
      
      peak.segments$Low.boundary[i] = temp.low 
      peak.segments$High.boundary[i] = temp.high
      peak.segments$Max.resp[i] = temp.rate
      peak.segments$Mid.peaks[i] = temp.mid
      
      temp.low = temp.high  
      
    }
  }
  
databin<-select(peak.segments, "Max.resp","Mid.peaks")
colnames(databin)<-c("max_rate","mid_conc")
####
plot1<-ggplot()+ geom_point(data=databin, aes(x=mid_conc, y=max_rate))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#8073ac")+geom_smooth(method="lm", formula=(y~log(x)))+
  #stat_poly_line(color="black") +
  #stat_poly_eq(label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('1/NPOC ('*mg~g^-1*')'))+ylab(bquote('Respiration rate ('*mg~h^-1~g^-1*')'))
plot1


library(ggpmisc)
x<-databin$mid_conc
y<-databin$max_rate
mod2 = summary(lm(y~log(x)))
  

###plotting the observations and constrained boundary
obv<-select(dataset, "respC","xlab")

plot1<-ggplot()+ geom_point(data=obv, aes(x=xlab, y=respC),shape=1,stroke=1,size=2, color="#8073ac")+geom_point(data=databin, aes(x=mid_conc, y=max_rate),shape=16,stroke=1,size=2, color="#2d004b")+geom_smooth(data=databin, aes(x=mid_conc, y=max_rate),method="lm", formula=(y~log(x)), color="#2d004b")+scale_y_continuous(breaks=c(0,0.2,0.4,0.6,0.8))+
    geom_text(aes(12, 0.7), label=paste0("R^2 == ",round(mod2$r.squared,2)), color = "#32287d", parse = T)+
    geom_text(aes(12, 0.6), label="(p < 0.001) ",color = "#32287d")+
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('1/NPOC ('*mgC~g^-1*')'))+ylab(bquote('Respiration rate ('*mgC~g^-1~h^-1*')'))
plot1

pdf("rate_fitting_new.pdf", width=3.5, height=3)
plot1
dev.off() 

```


## #############################################################################################################################################
#mechanistic modeling section

```{r theoretical}
#given npoc range 0-1

# Load required package
library(ggplot2)

# Define parameters
Vmax <- 1.0    # maximum rate constant
Cb   <- 1.0    # biomass multiplier
y    <- 1.0    # stoichiometric coefficient
p    <- 1.0    # accessibility coefficient

# Generate a sequence of 1/OC values
x <- seq(0, 5, length.out = 500)  # x = 1/OC

# Compute respiration rate: R = Vmax * Cb * exp( - (y/p) * x )
R_the <- Vmax * Cb * exp(- (y / p) * x)

# Combine into a data frame
df_the <- data.frame(
  inv_OC = x,
  R      = R_the
)

# Plot
plot1<-ggplot(df_the, aes(x = inv_OC, y = R)) +
  geom_point(shape=1,size = 1,color = "#542788") +
  labs(
    x     = "1/NPOC",
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)
  
pdf("RvsinvOC.pdf", width=3.5, height=3)
plot1
dev.off() 

###adding thermodynamic control---[0.095-0.12]
# Generate a sequence of 1/OC values
x <- seq(0, 5, length.out = 500)  # x = 1/OC
y<-runif(500, min=0.1, max=1)
p=1
Cb=1
# Compute respiration rate: R = Vmax * Cb * exp( - (y/p) * x )
R <- Vmax * Cb * exp(- (y / p) * x)

# Combine into a data frame
df <- data.frame(
  inv_OC = x,
  R      = R
)

# Plot
plot1<-ggplot() +
  geom_point(df,mapping= aes(x = inv_OC, y = R), shape=1, size = 1,color = "#e08214") +geom_line(df_the, mapping=aes(x = inv_OC, y = R),shape=1,size = 1,color = "#542788")+
  labs(
    x     = "1/NPOC",
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)
  
pdf("RvsinvOC+y.pdf", width=3.5, height=3)
plot1
dev.off() 

#####Includeing p


###adding thermodynamic control---[0.095-0.12]
# Generate a sequence of 1/OC values
x <- seq(0, 5, length.out = 500)  # x = 1/OC
#y<-runif(500, min=0.1, max=1)
y=1
Cb<-rnorm(500, mean=1, sd=0.25)
p=1
# Compute respiration rate: R = Vmax * Cb * exp( - (y/p) * x )
R <- Vmax * Cb * exp(- (y / p) * x)
R_scale<-rescale(R, to=c(0,1))
# Combine into a data frame
df <- data.frame(
  inv_OC = x,
  R      = R_scale
)

# Plot
plot1<-ggplot() +
  geom_point(df,mapping= aes(x = inv_OC, y = R), shape=1, size = 1,color = "#e08214") +geom_line(df_the, mapping=aes(x = inv_OC, y = R),shape=1,size = 1,color = "#542788")+
  labs(
    x     = "1/NPOC",
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)
pdf("RvsinvOC+y+Cb25.pdf", width=3.5, height=3)
plot1
dev.off() 





###adding thermodynamic control---[0.095-0.12]
# Generate a sequence of 1/OC values
x <- seq(0, 5, length.out = 500)  # x = 1/OC
#y<-runif(500, min=0.1, max=1)
y=1
Cb<-1
p=runif(500, min=0.1, max=1)
# Compute respiration rate: R = Vmax * Cb * exp( - (y/p) * x )
R <- Vmax * Cb * exp(- (y / p) * x)
R_scale<-rescale(R, to=c(0,1))
# Combine into a data frame
df <- data.frame(
  inv_OC = x,
  R      = R_scale
)

# Plot
# Plot
plot1<-ggplot() +
  geom_point(df,mapping= aes(x = inv_OC, y = R), shape=1, size = 1,color = "#e08214") +geom_line(df_the, mapping=aes(x = inv_OC, y = R),shape=1,size = 1,color = "#542788")+
  labs(
    x     = "1/NPOC",
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)
  
pdf("RvsinvOC+p.pdf", width=3.5, height=3)
plot1
dev.off() 





```



## ##############################################################################################################
##Mechanistic model scenarios with measurements
```{r sep}
##note that biomass reported as log10 (cell counts)
##load processed data that combines FTICR and site-level characterization
##fixing units both rate and concentration are in mg g-1
##original unit mgDO_per_L_per_h, convert mgDO g-1 to mgC g-1

library(dplyr)
library(readr)
library(purrr)

process_site <- function(path, filter_lambda = FALSE) {
  read_csv(path, col_types = cols(site = col_character())) %>%
    mutate(
      factor = (water_mass + 10) * 0.01 / sed_mass,
      respC  = rate * factor * (12 / 32),
      npoc   = conc * factor
    ) %>%
    { if (filter_lambda) filter(., lambda > 0) else . } %>%
    select(-factor)
}

files <- c("up_all.csv", "mid_all.csv", "low_all.csv")
names(files) <- c("up", "mid", "low")

# Process and filter each into its own data frame
data_list <- map(files, ~ process_site(.x, filter_lambda = TRUE))

up_v  <- data_list$up
mid_v <- data_list$mid
low_v <- data_list$low
```


##running model scenario 1, FTICR data and NPOC

```{r scen1}
library(dplyr)
library(tidyr)   
library(readr)   
library(purrr)   

###########################
all_data <- bind_rows(
  up_v  %>% mutate(level = "up"),
  mid_v %>% mutate(level = "mid"),
  low_v %>% mutate(level = "low")
)


probs <- c(q05 = 0.05, q25 = 0.25, q50 = 0.50, q75 = 0.75, q95 = 0.95)

summary_all <- all_data %>%
  drop_na() %>%
  mutate(
    pr1 = exp(-abs(stoichMet_donor) / npoc),
    pr2 = (3 / ne) * exp(-abs(stoichMet_donor) / npoc)
  ) %>%
  group_by(site, Position) %>%
  summarise(
    # Means for other numeric columns, excluding pr1/pr2
    across(
      where(is.numeric) & -any_of(c("pr1", "pr2")),
      ~ mean(.x, na.rm = TRUE),
      .names = "{.col}_mean"
    ),
    # Scalar quantiles for pr1 and pr2
    across(
      c(pr1, pr2),
      list(
        q05  = ~ quantile(.x, 0.05, na.rm = TRUE),
        q50  = ~ quantile(.x, 0.50, na.rm = TRUE),
        q95  = ~ quantile(.x, 0.95, na.rm = TRUE)
        ),
      .names = "{.col}_{.fn}"
    ),
    .groups = "drop"
  ) %>%
  select(site, Position, everything())




write_csv(summary_all, "new_sum_all_levels.csv")
assign("summary_all", summary_all, envir = .GlobalEnv)

# Inspect
head(summary_all)

## Create data visualization

## Ranges (q05–q95)
df_minmax <- summary_all %>%
  select(site, Position, matches("^pr[12]_(q05|q95)$")) %>%
  pivot_longer(
    cols = -c(site, Position),
    names_to = c("variable", "stat"),
    names_sep = "_",
    values_to = "value"
  ) %>%
  pivot_wider(
    id_cols    = c(site, Position, variable),
    names_from = stat,
    values_from = value
  ) %>%
  mutate(across(c(q05, q95), as.numeric))

## Points (q50)
df_pts <- summary_all %>%
  select(site, Position, matches("^pr[12]_q50$")) %>%
  pivot_longer(
    cols = -c(site, Position),
    names_to = c("variable", "stat"),
    names_sep = "_",
    values_to = "q50"
  ) %>%
  select(-stat) %>%
  mutate(q50 = as.numeric(q50))

## Join ranges and points (match on site + Position + variable)
df_plot <- left_join(
  df_minmax,
  df_pts,
  by = c("site", "Position", "variable")
)

## Optional: order sites for prettier x labels
df_plot <- df_plot %>% mutate(site = factor(site, levels = unique(site)))

## Plot: line = q05–q95, point = q50; color/group by Position, facet by variable
ggplot(df_plot, aes(x = site, group = Position, color = Position)) +
  geom_linerange(
    aes(ymin = q05, ymax = q95),
    position = position_dodge(width = 0.6),
    linewidth = 0.9   # use linewidth (ggplot2 >= 3.4)
  ) +
  geom_point(
    aes(y = q50),
    position = position_dodge(width = 0.6),
    size = 2
  ) +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    x = "Site",
    y = "pr value",
    color = "Position",
    title = "pr1 & pr2: 5–95% range (line) with median (point)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )


```



###rescale data for final plot
```{r rescale data}

##rescale data
library(dplyr)
library(readr)

## (Optional) If your columns are named q05/q50/q95, rename to p05/p50/p95
summary_all <- summary_all %>%
  rename_with(~ sub("q", "p", .x),
              matches("^pr[12]_q(05|50|95)$"))

## Columns to scale
pr1_cols <- c("pr1_p05", "pr1_p50", "pr1_p95")
pr2_cols <- c("pr2_p05", "pr2_p50", "pr2_p95")

## Safe rescale to [0,1]
rescale01 <- function(x) {
  r <- range(x, na.rm = TRUE)
  if (!all(is.finite(r)) || diff(r) == 0) return(ifelse(is.na(x), NA_real_, 0))
  (x - r[1]) / diff(r)
}

# Compute one range per variable across its p05/p50/p95 columns
rng1 <- range(unlist(summary_all[pr1_cols]), na.rm = TRUE)
rng2 <- range(unlist(summary_all[pr2_cols]), na.rm = TRUE)
span1 <- diff(rng1); span2 <- diff(rng2)

df_scaled <- summary_all %>%
  mutate(
    across(all_of(pr1_cols),
      ~ if (span1 == 0) 0 else (.x - rng1[1]) / span1,
      .names = "{.col}_scaled"
    ),
    across(all_of(pr2_cols),
      ~ if (span2 == 0) 0 else (.x - rng2[1]) / span2,
      .names = "{.col}_scaled"
    )
  ) %>%
  mutate(inv_npoc = 1 / npoc_mean)


## Long format for plotting p05/p50/p95
pr_long <- df_scaled %>%
  select(site, inv_npoc, matches("^pr[12]_(p05|p50|p95)_scaled$")) %>%
  pivot_longer(
    cols = matches("^pr[12]_(p05|p50|p95)_scaled$"),
    names_to = c("variable", "stat"),
    names_pattern = "(pr[12])_(p05|p50|p95)_scaled",
    values_to = "value"
  )

## Quick plot: p05, p50, p95 for pr1 & pr2
ggplot(pr_long, aes(x = inv_npoc, y = value, color = variable, shape = stat)) +
  geom_point(size = 2, alpha = 0.85) +
  #geom_smooth(aes(linetype = stat), method = "lm", se = FALSE) +
  scale_color_manual(
    values = c(pr1 = "#b35806", pr2 = "#fdb863"),
    labels = c("pr1", "pr2"),
    name   = "Variable"
  ) +
  scale_shape_manual(
    values = c(p05 = 25, p50 = 16, p95 = 24),   # ▼, ●, ▲ (filled)
    labels = c("p05", "p50", "p95"),
    name   = "Statistic"
  ) +
  scale_linetype_manual(
    values = c(p05 = "dotted", p50 = "solid", p95 = "dashed"),
    labels = c("p05", "p50", "p95"),
    name   = "Statistic"
  ) +
  labs(
    x     = expression(1/OC),
    y     = "Scaled pr value",
    title = "p05, p50, p95 of pr1 & pr2 vs. 1/OC"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom"
  )

###############

# Observed rates
comp_df <- df_scaled %>%
  mutate(
    res_scaled = (respC_mean - min(respC_mean, na.rm = TRUE)) /
                 (max(respC_mean, na.rm = TRUE) - min(respC_mean, na.rm = TRUE))
  ) %>%
  select(site,Position, inv_npoc, res_scaled) %>%
  tidyr::drop_na()

# Start from df_scaled 
pr_for_plot <- df_scaled %>%
  select(site, inv_npoc, matches("^pr[12]_(p05|p50|p95)_scaled$")) %>%
  pivot_longer(
    cols = -c(site, inv_npoc),
    names_to = c("variable", "stat"),
    names_pattern = "(pr[12])_(p\\d{2})_scaled",
    values_to = "value"
  ) %>%
  pivot_wider(
    id_cols    = c(site, inv_npoc, variable),
    names_from = stat,
    values_from = value
  ) %>%
  mutate(variable = factor(variable, levels = c("pr1", "pr2")))

##plot----------------------------------------------------------

plot1<-ggplot() +
  # p05–p95 ribbon by variable
  geom_ribbon(
    data = pr_for_plot,
    aes(x = inv_npoc, ymin = p05, ymax = p95, fill = variable),
    alpha = 0.3, show.legend = TRUE
  ) +
  # predicted p50 (solid points), colored by variable
  geom_point(
    data = pr_for_plot,
    aes(x = inv_npoc, y = p50, color = variable, shape = "p50"),
    size = 2, alpha = 0.9, show.legend = TRUE
  ) +
  # optional smooth for predicted p50 median
  geom_smooth(
    data = pr_for_plot,
    aes(x = inv_npoc, y = p50, color = variable),
    method = "loess", se = FALSE, linewidth = 0.7, show.legend = FALSE
  ) +
  # observed data (black solid points)
  geom_point(
    data = comp_df,
    aes(x = inv_npoc, y = res_scaled, color = "Observed", shape = "Observed"),
    size = 2, alpha = 0.9, show.legend = TRUE
  ) +
  # scales
  scale_fill_manual(
    values = c(pr1 = "#b35806", pr2 = "#fdb863"),
    name   = "Predicted (ribbon)"
  ) +
  scale_color_manual(
    values = c(pr1 = "#b35806", pr2 = "#fdb863", Observed = "#8073ac"),
    breaks = c("pr1", "pr2", "Observed"),
    labels = c("pr1 (pred)", "pr2 (pred)", "Observed"),
    name   = "Series"
  ) +
  scale_shape_manual(
    values = c(`p50` = 16, `Observed` = 16),  # 16: solid circle; 21: filled circle (uses color)
    labels = c("Predicted p50", "Observed"),
    name   = "Points"
  ) +
  scale_linetype_manual(
    values = c(`Observed` = "dotdash"),
    name   = "Smooth"
  ) +
  labs(
    x     = "1/NPOC",
   y = expression(italic(R)[scaled]~"(Observed & Predicted)")
  ) +  theme_pubr(border=TRUE)+theme( legend.position = "right")


pdf("FT_pr1_pr2_new2.pdf", width=5, height=3)
plot1
dev.off() 



## Stats

df<-df_scaled%>%
  select(site, Position, pr1_p50_scaled, pr2_p50_scaled)%>%
  left_join(comp_df, join_by(site, Position))

# Load needed package
library(Metrics)  # for rmse()

# Function to compute correlation-based R² and RMSE
model_stats <- function(obs, pred) {
  # Remove NA pairs if any
  idx <- complete.cases(obs, pred)
  obs <- obs[idx]
  pred <- pred[idx]
  
  # Correlation-based R² (always >= 0)
  r2 <- cor(obs, pred)^2
  
  # RMSE
  rmse_val <- rmse(obs, pred)
  
  return(list(R2 = r2, RMSE = rmse_val))
}

# Calculate stats for each prediction column
stats_pr1 <- model_stats(df$res_scaled, df$pr1_p50_scaled)
stats_pr2 <- model_stats(df$res_scaled, df$pr2_p50_scaled)

# Print results
stats_pr1
stats_pr2





```


##playing with some residual plot ideas--------
```{r residual}
#Load WHONDRS S19S data (presence/absence)
geodata <- read.csv('v4_WHONDRS_S19S_Metadata.csv')
geosub<- geodata[geodata$Country=="USA", ]


df_geo<-geosub[c("Sample_ID", "Stream_Order","MS_Latitude_dec.deg","MS_Longitude_dec.deg","SW_pH","SW_Temp_degC","DO_mg.per.L" )]
colnames(df_geo)<-c("ID","Stream_order","Latitude", "Longitude","pH","Temp","DO")
df_geo[df_geo == "Not_Provided"] <- NA

#fix rows 
num_text_cols <- c("pH", "Temp", "DO")

df_geo <- df_geo %>%
  mutate(
    across(all_of(num_text_cols), ~ parse_number(.x), .names = "{.col}")
  )



# If you kept pr_for_plot from earlier (site, inv_npoc, variable, p05, p50, p95):
# Join observed to predicted, then compute residuals
df_resids <- pr_for_plot %>%
  inner_join(
    comp_df %>% select(site, inv_npoc, res_scaled),
    by = c("site", "inv_npoc")
  ) %>%
  mutate(
    resid       = res_scaled - p50,
    band_width  = p95 - p05,
    # normalized by band width (useful for scale-free check)
    resid_norm  = resid / ifelse(band_width == 0, NA_real_, band_width),
    outside     = case_when(
      res_scaled > p95 ~ "above p95",
      res_scaled < p05 ~ "below p05",
      TRUE             ~ "inside"
    )
  )

##residual vs predictor (check bias across 1/OC)
res1<- ggplot(df_resids, aes(inv_npoc, resid, color = variable)) +
  geom_hline(yintercept = 0, linetype = "dashed") + scale_y_continuous(limits=c(-1,1))+
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE) + scale_color_manual(
    values = c("#b35806",  "#fdb863"))+
  labs(x = expression(1/NPOC), y = "Residual (Observed - Predicted)") +
  theme_pubr(border=TRUE)+theme( legend.position = "right")


pdf("resids_pr1_pr2_new.pdf", width=4.2, height=3)
res1
dev.off() 


##match sample IDs
unify_id4 <- function(x) {
  x <- as.character(x)
  id4 <- str_extract(x, "\\d{4}$")        # grab last 4 digits
  str_pad(id4, width = 4, pad = "0")      # ensure zero-padded
}


meta_clean <- df_geo %>%
  mutate(site_id4 = unify_id4(ID)) %>%
  select(site_id4, Stream_order, pH, Temp, DO, Latitude, Longitude)

resids_clean <- df_resids %>%
  mutate(site_id4 = unify_id4(site))

df_resids_meta <- resids_clean %>%
  left_join(meta_clean, by = "site_id4")

## plot residuals by Stream order (boxplot + points) 
res2<- ggplot(df_resids_meta, aes(x = factor(Stream_order), y = resid, color = variable)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_boxplot(width = 0.7, outlier.alpha = 0.25,
               position = position_dodge(width = 0.6)) +
  geom_point(size = 1.8, alpha = 0.6,
             position = position_jitterdodge(jitter.width = 0.15,
                                             jitter.height = 0,
                                             dodge.width  = 0.6)) +
  labs(x = "Stream order", y = "Residual (Observed - Pred p50)", color = "Series") +
   theme_pubr(border=TRUE)+theme( legend.position = "right")

pdf("res_SO_pr1_pr2.pdf", width=4.2, height=3)
res2
dev.off() 

#--

df_resids_meta <- df_resids_meta %>%
  mutate(
    pH_bin   = cut(pH,   breaks = seq(floor(min(pH,   na.rm=TRUE)),
                                          ceiling(max(pH, na.rm=TRUE)), by = 0.5),
                   include.lowest = TRUE, right = FALSE, dig.lab = 3),
    Temp_bin = cut(Temp, breaks = seq(floor(min(Temp, na.rm=TRUE)),
                                          ceiling(max(Temp, na.rm=TRUE)), by = 6),
                   include.lowest = TRUE, right = FALSE),
        DO_bin = cut(DO, breaks = seq(floor(min(DO, na.rm=TRUE)),
                                          ceiling(max(DO, na.rm=TRUE)), by = 2),
                   include.lowest = TRUE, right = FALSE)
  )

# ---plot by bins
res3<- ggplot(df_resids_meta, aes(x = DO_bin, y = resid, color = variable)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_boxplot(width = 0.7, outlier.alpha = 0.25,
               position = position_dodge(width = 0.6)) +
  geom_point(size = 1.8, alpha = 0.6,
             position = position_jitterdodge(jitter.width = 0.15,
                                             jitter.height = 0,
                                             dodge.width  = 0.6)) +
  labs(x = "DO", y = "Residual (Obs - Pred p50)", color = "Series") + theme_pubr(border=TRUE)+theme( legend.position = "right")+theme(axis.text.x = element_text(angle = 45, hjust = 1))

pdf("res_DO_pr1_pr2.pdf", width=4.2, height=3.2)
res3
dev.off() 



#### stats

compute_metrics <- function(dat) {
  dat <- dat %>% filter(is.finite(res_scaled), is.finite(p50))
  n <- nrow(dat)
  if (n < 2) {
    return(tibble(
      n = n, rmse = NA_real_, mae = NA_real_, bias = NA_real_,
      r2_corr = NA_real_, r2_trad = NA_real_, ccc = NA_real_,
      coverage_90 = NA_real_, over_p95 = NA_real_, under_p05 = NA_real_,
      sharp_mean = NA_real_, sharp_median = NA_real_,
      calib_slope = NA_real_, calib_intercept = NA_real_
    ))
  }
  y  <- dat$res_scaled
  yhat <- dat$p50

  # core errors
  err <- y - yhat
  rmse <- sqrt(mean(err^2, na.rm = TRUE))
  mae  <- mean(abs(err), na.rm = TRUE)
  bias <- mean(err, na.rm = TRUE)

  # R^2 (correlation-based) & traditional
  r <- suppressWarnings(cor(y, yhat, use = "complete.obs"))
  r2_corr <- if (is.finite(r)) r^2 else NA_real_
  sse <- sum((y - yhat)^2, na.rm = TRUE)
  sst <- sum((y - mean(y, na.rm = TRUE))^2, na.rm = TRUE)
  r2_trad <- if (sst > 0) 1 - sse/sst else NA_real_

  # Lin's Concordance Correlation Coefficient (CCC)
  mu_y   <- mean(y, na.rm = TRUE)
  mu_yh  <- mean(yhat, na.rm = TRUE)
  sd_y   <- stats::sd(y, na.rm = TRUE)
  sd_yh  <- stats::sd(yhat, na.rm = TRUE)
  ccc <- if (is.finite(r) && is.finite(sd_y) && is.finite(sd_yh)) {
    2 * r * sd_y * sd_yh / (sd_y^2 + sd_yh^2 + (mu_y - mu_yh)^2)
  } else NA_real_

  # coverage and sharpness of the 90% band
  coverage_90 <- mean(dat$res_scaled >= dat$p05 & dat$res_scaled <= dat$p95, na.rm = TRUE)
  over_p95    <- mean(dat$res_scaled >  dat$p95, na.rm = TRUE)
  under_p05   <- mean(dat$res_scaled <  dat$p05, na.rm = TRUE)
  sharp_mean   <- mean(dat$band_width, na.rm = TRUE)
  sharp_median <- stats::median(dat$band_width, na.rm = TRUE)

  # calibration: obs ~ pred
  fit <- try(glm(res_scaled ~ p50, data = dat), silent = TRUE)
  if (inherits(fit, "try-error")) {
    slope <- NA_real_; intercept <- NA_real_
  } else {
    co <- coef(fit)
    intercept <- unname(co[1]); slope <- unname(co[2])
  }

  tibble(
    n = n,
    rmse = rmse, mae = mae, bias = bias,
    r2_corr = r2_corr, r2_trad = r2_trad, ccc = ccc,
    coverage_90 = coverage_90, over_p95 = over_p95, under_p05 = under_p05,
    sharp_mean = sharp_mean, sharp_median = sharp_median,
    calib_slope = slope, calib_intercept = intercept
  )
}

# ---- 3) Metrics by model (pr1 vs pr2) ----
stats_by_model <- df_resids %>%
  group_by(variable) %>%
  group_modify(~ compute_metrics(.x)) %>%
  ungroup()


```








## model scenario II, adding microbial cell counts as biomass on top of NPOC and FTICR
## simulations with and without thermodynamic control as well
```{r cb}
library(dplyr)

# Define your new rate columns
pr3_cols <- "pr3"
pr4_cols <- "pr4"
pr5_cols <- "pr5"
pr6_cols <- "pr6"

# Define rescale function
# safe 0–1 rescale
rescale01 <- function(x) {
  r <- range(x, na.rm = TRUE)
  if (!all(is.finite(r)) || diff(r) == 0) return(ifelse(is.na(x), NA_real_, 0))
  (x - r[1]) / diff(r)
}


df_processed <- df_scaled %>%
  # 1. Compute pr3 and pr4
  mutate(
    pr3 = exp(-abs(1) / npoc_mean) * biomass_mean, ###only consider Cb and NPOC, no thermodynamic control
    pr4 = pr2_p05 * biomass_mean, 
    pr5 = pr2_p50 * biomass_mean,   ###pr2 prediction+ Cb
    pr6 = pr2_p95 * biomass_mean,  
  ) %>%
 
  drop_na() 

  # one common min/max for pr4–pr6 (preserves p05–p50–p95 spacing)
rng456  <- range(c(df_processed$pr4, df_processed$pr5, df_processed$pr6), na.rm = TRUE)
span456 <- diff(rng456)

df_processed <- df_processed %>%
  mutate(
    pr4_scaled = if (span456 == 0) 0 else (pr4 - rng456[1]) / span456,
    pr5_scaled = if (span456 == 0) 0 else (pr5 - rng456[1]) / span456,
    pr6_scaled = if (span456 == 0) 0 else (pr6 - rng456[1]) / span456,
    pr3_scaled = rescale01(pr3),                     # scaled independently
    res_scaled = rescale01(respC_mean)               # obs scaled 0–1 for overlay
  ) %>%
  select(site, Position, inv_npoc,
         res_scaled, pr3_scaled, pr4_scaled, pr5_scaled, pr6_scaled, biomass_mean)


# Inspect
head(df_processed)

## plot
colnames(df_processed)<-c("site","Position","inv_npoc","Obv","Pred3","Pred4","Pred5","Pred6","biomass")

upcomp_long <- df_processed %>%
  pivot_longer(
    cols      = c(Obv, Pred3, Pred4,Pred5, Pred6),  
    names_to  = "metric",
    values_to = "rate"
  )



## quick scatter plot
plot1<- ggplot(upcomp_long, aes(x = inv_npoc, y = rate, color = metric)) +
  geom_point(alpha = 0.8, size = 2) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed") +
  scale_color_manual(values=c("#8073ac","#b35806","#e08214", "#fdb863","#fee0b6"))+
  labs(
    x     = "1/NPOC",
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)+theme( legend.position = "right")

## shaded scatter plot 

plot2 <- ggplot() +
  # p05–p95 ribbon from Pred4/Pred6
  geom_ribbon(
    data = df_processed,
    aes(x = inv_npoc, ymin = Pred4, ymax = Pred6, fill = "Pred p05–p95"),
    alpha = 0.3, show.legend = TRUE
  ) +
  # median (p50) as solid points
  geom_point(
    data = df_processed,
    aes(x = inv_npoc, y = Pred5, color = "Pred p50"),
    size = 2, alpha = 0.8, show.legend = TRUE
  ) +
  # optional: overlay Pred3 (CB × NPOC-only) as a dashed line
  geom_point(
    data = df_processed,
    aes(x = inv_npoc, y = Pred3, color = "Pred3 (CB×NPOC)"),
    size=2, shape=16
  ) +
  # optional: overlay observations
  geom_point(
    data = df_processed,
    aes(x = inv_npoc, y = Obv, color = "Observed"),
    size = 2, alpha = 0.8, shape = 16, fill = "#8073ac"
  ) +
  scale_fill_manual(values = c("Pred p05–p95" = "#fdb863"), name = NULL) +
  scale_color_manual(
    values = c("Pred p50" = "#fdb863",
               "Pred3 (CB×NPOC)" = "#b35806",
               "Observed" = "#8073ac"),
    name = NULL
  ) +
  labs(
    x = "1/NPOC",
    y = expression(italic(R)[scaled]~"(Observed & Predicted)")
  ) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("FT_pr3_pr6_new.pdf", width=5.2, height=3)
plot2
dev.off() 



## Stats
library(Metrics)  # for rmse()

pred_cols <- c("Pred3", "Pred4", "Pred5", "Pred6")

stats_list <- lapply(pred_cols, function(col) {
  
  idx  <- complete.cases(df_processed$Obv, df_processed[[col]])
  obs  <- df_processed$Obv[idx]
  pred <- df_processed[[col]][idx]
  
  # Correlation-based R² (always >= 0)
  r2 <- cor(obs, pred)^2
  
  rmse_val <- rmse(obs, pred)
  
  data.frame(
    Model = col,
    R2    = r2,
    RMSE  = rmse_val
  )
})

results <- do.call(rbind, stats_list)

print(results)




#######
upcomp_long <- df_processed %>%
  pivot_longer(
    cols      = c(Pred3, Pred5),  
    names_to  = "metric",
    values_to = "rate"
  )




## quick scatter plot 1:1 line 
plot1<- ggplot(upcomp_long, aes(x = Obv, y = rate, color = metric)) +
  geom_point(alpha = 0.8, size = 2) + ylim(values=c(0,1))+geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  scale_color_manual(values=c("#b35806", "#fdb863","#fee0b6"))+
  labs(
    x     = expression(R[obv]),
    y     = expression(R[pred])
  ) +  theme_pubr(border=TRUE)+theme( legend.position = "right")




# Build residuals for pr3 and pr5
df_resid35 <- df_processed %>%
  select(site, Position, inv_npoc, Obv, Pred3, Pred5) %>%
  pivot_longer(
    cols = c(Pred3, Pred5),
    names_to = "model",
    values_to = "pred"
  ) %>%
  mutate(
    model = recode(model,
                   Pred3 = "pr3",
                   Pred5 = "pr5"),
    resid = Obv - pred
  ) %>%
  drop_na(inv_npoc, resid)

# Residual vs predictor (1/OC)
p_resid <- ggplot(df_resid35, aes(x = inv_npoc, y = resid, color = model)) +
  geom_hline(yintercept = 0, linetype = "dashed") + scale_y_continuous(limits=c(-1,1))+
  geom_point(alpha = 0.6, size = 2) +
  geom_smooth(se = FALSE, linewidth = 0.8) +
  scale_color_manual(
    values = c("pr3" = "#b35806",
               "pr5"  = "#fdb863"),
    name = "Model"
  ) +
  labs(
    x = expression(1/NPOC),
    y = "Residual (Observed - Predicted)"
  ) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

p_resid



pdf("resid_pr3_pr5_biomass.pdf", width=4, height=3)
p_resid
dev.off() 


```



## model scenario III, chemistry and physics

```{r phy}
library(dplyr)

# Define your new rate columns
pr7_cols <- "pr7"
pr8_cols <- "pr8"
pr9_cols <- "pr9"


df_processed <- all_data %>%
  drop_na() %>%
  mutate(
    pr7 = (3 / ne) * exp(-abs(stoichMet_donor) / (0.05*npoc)) ,
    pr8 = (3 / ne)* exp(-abs(stoichMet_donor) / (0.25*npoc)) ,
    pr9 = (3 / ne) * exp(-abs(stoichMet_donor) / (0.5*npoc)) 
  ) %>%
  group_by(site, Position) %>%
  summarise(
    # Means for other numeric columns, excluding pr1/pr2
    across(
      where(is.numeric) & -any_of(c("pr7", "pr8","pr9")),
      ~ mean(.x, na.rm = TRUE),
      .names = "{.col}_mean"
    ),
    # Scalar quantiles for pr789
    across(
      c(pr7, pr8,pr9),
      list(
        q05  = ~ quantile(.x, 0.05, na.rm = TRUE),
        q50  = ~ quantile(.x, 0.50, na.rm = TRUE),
        q95  = ~ quantile(.x, 0.95, na.rm = TRUE)
        ),
      .names = "{.col}_{.fn}"
    ),
    .groups = "drop"
  ) %>%
  mutate(inv_npoc = 1 / npoc_mean,
        res_scaled = rescale01(respC_mean)  
         )%>%
  select(site, Position, everything())


# Inspect
head(df_processed)


# ---- choose your x column (from the *_mean columns you created) ----
# If your x is named differently, change this to that column name.
x_col <- "inv_npoc"

# Build a long data frame with q05/q50/q95 per metric
quant_long <- df_processed %>%
  select(site, Position, all_of(x_col),
         matches("^pr7_q(05|50|95)$"),
         matches("^pr8_q(05|50|95)$"),
         matches("^pr9_q(05|50|95)$")) %>%
  pivot_longer(
    cols = matches("^pr[789]_q(05|50|95)$"),
    names_to = c("metric","stat"),
    names_pattern = "(pr[789])_q(05|50|95)",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, pr7 = "Pred7", pr8 = "Pred8", pr9 = "Pred9")
  ) %>%
  pivot_wider(names_from = stat, values_from = value) %>%
  # keep a clean factor order
  mutate(metric = factor(metric, levels = c("Pred7","Pred8","Pred9")))

# ---- Step 2: rescale each metric's p05/p50/p95 to 0–1 ----
quant_scaled <- quant_long %>%
  group_by(metric) %>%
  mutate(
    qmin = min(`05`, `50`, `95`, na.rm = TRUE),
    qmax = max(`05`, `50`, `95`, na.rm = TRUE),
    `05` = (`05` - qmin) / (qmax - qmin),
    `50` = (`50` - qmin) / (qmax - qmin),
    `95` = (`95` - qmin) / (qmax - qmin)
  ) %>%
  ungroup() %>%
  select(-qmin, -qmax)

# Extract observational data
obs_df <- df_processed %>%
  select(site, Position, all_of(x_col), res_scaled)
colnames(obs_df)<-c("site","Position","inv_npoc","res")
# palettes
col_pal  <- c(Pred7 = "#b35806", Pred8 = "#fdb863", Pred9 = "#fee0b6",res= "#8073ac")
fill_pal <- c(Pred7 = "#b35806", Pred8 = "#fdb863", Pred9 = "#fee0b6",res= "#8073ac")

# ---- plot: per-metric ribbon (q05–q95) + p50 points ----
plot3 <- ggplot(quant_scaled, aes(x = .data[[x_col]])) +
  # shaded ribbons (rescaled 0–1)
  geom_ribbon(aes(ymin = `05`, ymax = `95`, fill = metric),
              alpha = 0.4, color = NA) +
  # median points
  geom_point(aes(y = `50`, color = metric), size = 2, alpha = 0.9) +  geom_smooth(aes(y = `50`, color = metric),
              method = "loess", se = FALSE, linewidth = 1.2, linetype = "solid") +
  # observed data
  geom_point(data = obs_df,
             aes(x = .data[[x_col]], y = res, color="res"),
             inherit.aes = FALSE,
             size = 2, alpha = 0.9, shape = 16) +
  scale_color_manual(values = col_pal, name = NULL) +
  scale_fill_manual(values = fill_pal,  name = NULL) +
  labs(x = "1/NPOC",  y = expression(italic(R)[scaled]~"(Observed & Predicted)")) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

print(plot3)


pdf("FT_pr7_pr8_pr9.pdf", width=4.4, height=3)
plot3
dev.off() 



##333333333quick residual plot
# build residuals: Observed - Predicted

df_res <- df_processed %>%
  mutate(
    pr7_q50_scaled = scales::rescale(pr7_q50, to = c(0, 1)),
    pr8_q50_scaled = scales::rescale(pr8_q50, to = c(0, 1)),
    pr9_q50_scaled = scales::rescale(pr9_q50, to = c(0, 1))
  )

df_res <- df_res %>%
  mutate(
    residual_pr7 = res_scaled - pr7_q50_scaled,
    residual_pr8 = res_scaled - pr8_q50_scaled,
    residual_pr9 = res_scaled - pr9_q50_scaled
  )

library(Metrics)

model_stats <- function(obs, pred) {
  idx <- complete.cases(obs, pred)
  obs <- obs[idx]
  pred <- pred[idx]

  r2 <- cor(obs, pred)^2
  rmse_val <- rmse(obs, pred)

  tibble(R2 = r2, RMSE = rmse_val)
}

stats_all <- tibble(
  model = c("pr7", "pr8", "pr9"),
  R2 = c(
    cor(df_res$res_scaled, df_res$pr7_q50_scaled, use = "complete")^2,
    cor(df_res$res_scaled, df_res$pr8_q50_scaled, use = "complete")^2,
    cor(df_res$res_scaled, df_res$pr9_q50_scaled, use = "complete")^2
  ),
  RMSE = c(
    rmse(df_res$res_scaled, df_res$pr7_q50_scaled),
    rmse(df_res$res_scaled, df_res$pr8_q50_scaled),
    rmse(df_res$res_scaled, df_res$pr9_q50_scaled)
  )
)
stats_all



# plot
df_long <- df_res %>%
  pivot_longer(
    cols = starts_with("residual_pr"),
    names_to = "model",
    values_to = "residual"
  )




p_res <- ggplot(df_long, aes(x =inv_npoc, y = residual, color = model)) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.6) + 
  geom_point(alpha = 0.8, size = 2) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +coord_cartesian(ylim = c(-1, 1)) +  
  scale_color_manual(values = c("#b35806","#fdb863", "#fee0b6")) +
  labs(
    x = "1/NPOC",
    y = expression(Residual~"("~Observed - Predicted~")")
  ) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

print(p_res)


pdf("resid_pr7_pr8_pr9.pdf", width=4.5, height=3)
p_res
dev.off() 




```


###Scenario IV============================================================================================================
### Fitting Vh
```{r cb}
library(dplyr)

# use pr2 (y and mu_max)+ biomass at 50% quantile (pr5 in previous simulations)

prm_cols <- "prm"



df_processed <- df_scaled %>%
  # 1. Compute pr3 and pr4
  mutate(
    prm = pr2_p50 * biomass_mean,   ###pr2 prediction+ Cb
  ) %>%
 
  drop_na() 
```

#calculate D50
# Grain-size class bounds in mm 
```{r d50}

d_min <- c(
  clay   = 0.0005,  # 0.5 µm
  silt   = 0.002,   # 2 µm
  fine   = 0.053,   # 53 µm (fine sand)
  med    = 0.25,    # 0.25 mm (medium sand)
  coarse = 0.5      # 0.5 mm (coarse sand; upper bound defined below)
)

d_max <- c(
  clay   = 0.002,
  silt   = 0.053,
  fine   = 0.25,
  med    = 0.5,
  coarse = 2.0      # 2 mm (you can change this)
)

calc_d50 <- function(pct_vec, d_min, d_max) {
  # pct_vec: numeric vector of % in each class, ordered same as d_min/d_max
  # d_min, d_max: numeric vectors of same length (mm)
  
  # geometric mid-size for each class
  log_d_mid <- (log10(d_min) + log10(d_max)) / 2
  d_mid <- 10^log_d_mid
  
  frac <- pct_vec / sum(pct_vec, na.rm = TRUE)
  F <- cumsum(frac)
  
  # index where cumulative fraction first >= 0.5
  i <- which(F >= 0.5)[1]
  
  if (length(i) == 0 || is.na(i)) {
    return(NA_real_)  # handle weird cases
  }
  
  if (i == 1) {
    F0 <- 0
    log_d0 <- log10(d_min[1])  # median somewhere in first class
  } else {
    F0 <- F[i - 1]
    log_d0 <- log_d_mid[i - 1]
  }
  
  F1 <- F[i]
  log_d1 <- log_d_mid[i]
  
  w <- (0.5 - F0) / (F1 - F0)
  log_d50 <- log_d0 + w * (log_d1 - log_d0)
  d50 <- 10^log_d50
  
  return(d50)
}

##
df_processed <- df_processed %>%
  rowwise() %>%
  mutate(
    d50_mm = calc_d50(
      pct_vec = c(clay_mean, silt_mean, fine_mean, med_mean, coarse_mean),
      d_min   = d_min,
      d_max   = d_max
    )
  ) %>%
  ungroup()



```

### model fitting 
```{r fit}
df_sub<-df_processed %>%
  select(site, Position, ne_mean, stoichMet_donor_mean, biomass_mean, ssa_tot_mean, respC_mean, npoc_mean, d50_mm, inv_npoc) %>%
  rename_with(~gsub("_mean$","", .x))

head(df_sub)

###calculating Vh
df_Vh <- df_sub %>%
  mutate(
    mu_max = 1,
    ratio  = respC / (mu_max * biomass),
    Vh = ifelse(
      !is.finite(ratio) | ratio <= 0 | ratio >= 1,
      NA_real_,  # avoid log problems and nonphysical negatives
      - (abs(stoichMet_donor) * inv_npoc) / log(ratio)
    )
  )

##inspect Vh distribution
ggplot(df_Vh, aes(x = log10(Vh))) +
  geom_histogram(bins = 30, fill = "orange", color = "black") +
  theme_bw()


### density distribution plot 
plot2 <- ggplot(df_Vh, aes(x = Vh)) + 
  geom_histogram(aes(y = ..density..),
                 binwidth = 0.05,
                 colour = "black", fill = "white") +
  geom_density(alpha = 0.2, fill = "#e08214") +
  scale_x_log10(
    name = "Vh (effective harvest volume)",
    breaks = c(1e-2, 1e-1, 1e0),
    labels = c(expression(10^-2), expression(10^-1), expression(10^0)),
    limits = c(1e-2, 1)   # <-- expand enough to include breaks
  ) +
  geom_vline(aes(xintercept = mean(Vh, na.rm = TRUE)),
             color = "#e08214", linetype = "dashed", size = 1) +
  theme_pubr(border = TRUE) +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 14, face = "bold")
  )

plot2

pdf("Vheff_fitted.pdf", width=3.2, height=3)
plot2
dev.off() 



df_Vh <- df_Vh %>%
  mutate(biomass_over_npoc = biomass / npoc)



plot1<-ggplot(data=df_Vh, aes(x=biomass_over_npoc, y=Vh))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left", label.y.npc="top", vjust=1)+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('Biomass/NPOC'))+ylab(bquote('Fitted Vh'))
plot1


pdf("Vh_vs_biomass_npoc.pdf", width=3.3, height=3)
plot1
dev.off() 



df_Vh <- df_Vh %>%
  mutate(npoc_over_ssa = npoc/ssa_tot)

plot1<-ggplot(data=df_Vh, aes(x=npoc_over_ssa, y=Vh))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "right", label.y.npc="top",hjust=1, vjust=1)+
  stat_poly_line(color="black") +  scale_x_log10(
    name = expression(log[10]~"(NPOC / SSA)"),
    breaks = c(1e-5, 1e-4, 1e-3),
    labels = c(expression(10^-5), expression(10^-4), expression(10^-3))
  )+
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+ylab(bquote('Fitted Vh'))
plot1


pdf("Vh_vs_npoc_ssa.pdf", width=3.3, height=3)
plot1
dev.off() 



plot2<-ggplot(df_Vh, aes(x = respC)) +
  geom_histogram(bins = 40, fill = "#e08214", color = "white", alpha = 0.8) +
  scale_x_log10(name="Respiration rate (mgC/g)",
                breaks = c(1e-4, 1e-3, 1e-2, 1e-1, 1),
                labels = c("1e-4", "1e-3", "1e-2", "1e-1", "1")) +
  labs(y = "Count")+theme_pubr(border=TRUE)
pdf("Rs_distribution.pdf", width=3.3, height=3)
plot2
dev.off() 



df_Vh <- df_Vh %>%
  mutate(bio_over_ssa = biomass/ssa_tot)

plot1<-ggplot(data=df_Vh, aes(x=log10(bio_over_ssa), y=Vh))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(Biomass/SSA)'))+ylab(bquote('Fitted Vh'))
plot1


pdf("Vh_vs_biomass_ssa.pdf", width=3.5, height=3)
plot1
dev.off() 



df_Vh <- df_Vh %>%
  mutate(ther_over_bio = abs(stoichMet_donor)/ssa_tot)

plot1<-ggplot(data=df_Vh, aes(x=log10(ther_over_bio), y=Vh))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(Therm/SSA)'))+ylab(bquote('Fitted Vh'))
plot1

pdf("Vh_vs_therm_npoc.pdf", width=3.5, height=3)
plot1
dev.off() 



df_Vh <- df_Vh %>%
  mutate(r_over_bio = d50_mm/ssa_tot)

plot1<-ggplot(data=df_Vh, aes(x=log10(r_over_bio), y=Vh))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(NPOC/d50)'))+ylab(bquote('Fitted Vh'))
plot1

pdf("Vh_vs_npoc_d50.pdf", width=3.5, height=3)
plot1
dev.off() 


#######Vh is more biochemically bounded##
##try looking into residuals
df_Vh <- df_Vh %>%
  mutate(
    B_over_DOM   = biomass / npoc,
    TD_over_DOM  = abs(stoichMet_donor) / npoc      # thermodynamic demand normalized by DOM
  )

m_bio <- lm(log10(Vh) ~ log10(B_over_DOM) + log10(TD_over_DOM), data = df_Vh)
summary(m_bio)

df_Vh <- df_Vh %>%
  mutate(
    Vh_resid = resid(m_bio)   # this is log10(Vh) residual
  )


m_resid_d50 <- lm(Vh_resid ~ log10(ssa_tot), data = df_Vh)
summary(m_resid_d50)

##residual analysis
ggplot(df_Vh, aes(x = ssa_tot, y = Vh_resid)) +
  geom_point() +
  scale_x_log10() +
  theme_bw()


###normalize Vh by biogeochemical term
df_Vh <- df_Vh %>%
  mutate(
    TD_over_DOM  = abs(stoichMet_donor) / npoc,
    Vh_norm_TD   = Vh / TD_over_DOM,
    B_over_DOM   = biomass / npoc,
    Vh_norm_BDOM = Vh / B_over_DOM
  )

# Test if normalized Vh has a d50 trend
lm(log10(Vh_norm_TD) ~ log10(ssa_tot), data = df_Vh) %>% summary()
lm(log10(Vh_norm_BDOM) ~ log10(ssa_tot), data = df_Vh) %>% summary()

##plots to contrast

plot1<-ggplot(data=df_Vh, aes(x=log10(ssa_tot), y=log10(Vh)))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(d50)'))+ylab(bquote('log10(Fitted Vh)'))
plot1


plot2<-ggplot(data=df_Vh, aes(x=log10(ssa_tot), y=log10(Vh_norm_TD)))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(ssa)'))+ylab(bquote('log10(Vh_norm_TD)'))
plot2
pdf("ssa_vs_TDnorm_Vh.pdf", width=3.5, height=3)
plot2
dev.off() 


plot3<-ggplot(data=df_Vh, aes(x=log10(ssa_tot), y=log10(Vh_norm_BDOM)))+ 
  geom_point(aes(),shape=1,stroke=1,size=2, color="#b35806")+
  stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x.npc = "left")+
  stat_poly_line(color="black") +
  #scale_y_continuous(limits=c(0,0.3))+
  #stat_poly_eq(use_label(c("adj.R2", "P")),label.x = 0.9) +
  theme_pubr(border=TRUE)+theme(legend.position="none")+theme(strip.text=element_text(size=14, face="bold"))+xlab(bquote('log10(ssa)'))+ylab(bquote('log10(Vh_norm_BDOM)'))
plot3
pdf("ssa_vs_BDOMnorm_Vh.pdf", width=3.5, height=3)
plot3
dev.off() 


###multivariate model
m_base <- lm(
  log10(Vh) ~ log10(B_over_DOM) + log10(TD_over_DOM) +
                log10(ssa_over_npoc) + log10(d50_mm),
  data = df_Vh
)

summary(m_base)

###fit a generalized additive model
library(mgcv)

m_gam <- gam(
  log10(Vh) ~ 
      s(log10(B_over_DOM)) +
      s(log10(TD_over_DOM)) +
      s(log10(ssa_over_npoc)) +
      s(log10(d50_mm)),
  data = df_Vh
)

summary(m_gam)
plot(m_gam, pages = 1)

##compare linear vs GAM models
AIC(m_base, m_gam) ###-287 vs -291## GAM does not outperform linear 
anova(m_base, m_gam, test = "F")

###calculate contributions

library(relaimpo)

imp <- calc.relimp(
  m_base, 
  type = c("lmg", "first", "last", "betasq")
)

imp

###testing an interaction model
m_interact <- lm(
  log10(Vh) ~ log10(B_over_DOM) * log10(ssa_over_npoc),
  data = df_Vh
)

summary(m_interact)
anova(m_base, m_interact)


library(pdp)

pdp_B <- partial(m_gam, pred.var = "B_over_DOM")
plotPartial(pdp_B)



m <- lm(log10(Vh) ~ log10(biomass/npoc) + log10(ssa_tot/npoc) + log10(d50_mm) + log10(ssa_tot)+ log10(abs(stoichMet_donor)),
        data = df_Vh)
summary(m)


library(mgcv)
gam_fit <- gam(log10(Vh) ~ s(log10(biomass/npoc)) + s(log10(ssa_tot/npoc)), data = df_Vh)
summary(gam_fit)


## back calculate rate from Vh and check at per peak level
df_peak<-all_data %>%
  select(site, Position, ne, stoichMet_donor, biomass, respC, npoc) 

df_peak_model <- df_peak %>%
  # 1. Add 1/OC
  mutate(inv_npoc = 1 / npoc) %>%
  
  # 2. Join fitted Vh from the summary-level dataframe
  left_join(
    df_Vh %>% select(site, Position, Vh),
    by = c("site", "Position")
  ) %>%
  
  # 3. Compute mu_max and modeled rate
  mutate(
    mu_max       = 3 / ne,
    respC_model  = mu_max * exp(-abs(stoichMet_donor) * inv_npoc / Vh) * biomass
  )


plot1<-ggplot(df_peak_model, aes(x = respC, y = respC_model, color = site)) +
  geom_point(alpha = 0.3, size = 1.5) + xlim(0,0.5)+
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  theme_bw()+theme(legend.position = "none") 


pdf("Vh_fit_check.pdf", width=6, height=4)
plot1
dev.off() 




df_fit <- df_Vh %>%
  filter(
    is.finite(Vh),
    is.finite(d50_mm),
    Vh > 0,
    d50_mm > 0
  ) %>%
  select(site, Position, d50_mm, Vh)

#######testing power-law with D50
fit_power <- lm(log10(Vh) ~ log10(d50_mm), data = df_fit)
summary(fit_power)

coef_power <- coef(fit_power)
alpha_power <- unname(coef_power["log10(d50_mm)"])
K_power     <- 10^(coef_power["(Intercept)"])
alpha_power
K_power


#######testing SSA model with D50
logKssa <- mean(log10(df_fit$Vh * df_fit$d50_mm), na.rm = TRUE)
K_ssa   <- 10^logKssa
K_ssa

##plot predictions
df_fit <- df_fit %>%
  mutate(
    Vh_power_pred = K_power * d50_mm^alpha_power,
    Vh_ssa_pred   = K_ssa   * d50_mm^(-1)
  )


library(ggplot2)

ggplot(df_fit, aes(x = Vh, y = Vh_ssa_pred)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +   # ← 1-to-1 line
  theme_bw() +
  labs(
    x = "Derived Vh",
    y = "Predicted Vh (Power-law)",
    title = "1-to-1 comparison: Power-law predicted Vh vs. derived Vh"
  )


# R² for power-law in log space
logVh      <- log10(df_fit$Vh)
logVh_pow  <- log10(df_fit$Vh_power_pred)
logVh_ssa  <- log10(df_fit$Vh_ssa_pred)

Rsq <- function(obs, pred) {
  1 - sum((obs - pred)^2) / sum((obs - mean(obs))^2)
}

Rsq_power <- Rsq(logVh, logVh_pow)
Rsq_ssa   <- Rsq(logVh, logVh_ssa)

Rsq_power
Rsq_ssa



library(minpack.lm)

fit_power <- nlsLM(
  Vh ~ K * d50_mm^alpha,
  data = df_fit,
  start = list(K = 1, alpha = -0.5)    # reasonable starting values
)

summary(fit_power)



```


####testing a KGML approach
```{r kgml}
##sete a fixed Vh value

Vh0 <- median(df_Vh$Vh, na.rm = TRUE)

##calculate mechanistic baseline+ resisual

df_kgml <- df_Vh %>%
  mutate(
    Vh0      = Vh0,                 # chosen baseline
    mu_max   = 1,              # your choice
    R_mech   = mu_max * exp(-abs(stoichMet_donor) / (Vh0 * npoc)) * biomass,
    logR_obs = log10(respC),
    logR_mech = log10(R_mech),
    dR       = logR_obs - logR_mech  # target for ML
  )

##visualize
plot1<-ggplot(df_kgml)+geom_point(aes(x=respC, y=dR))

cor(df_kgml$logR_obs, df_kgml$logR_mech, use = "complete.obs") ##0.53

library(yardstick)

df_kgml %>%
  metrics(truth = respC, estimate = R_mech)


###prep new data set

df_test<-df_processed %>%
  dplyr::select(site, Position, delGcat_mean, lambda_mean,ne_mean, stoichMet_donor_mean, biomass_mean, ssa_tot_mean, respC_mean, npoc_mean,clay_mean, silt_mean, fine_mean, med_mean, coarse_mean, d50_mm) %>%
  rename_with(~gsub("_mean$","", .x))

df_resid<- df_test %>%
  dplyr::left_join(
    df_kgml %>% 
      dplyr::select(site, Position, Vh0, R_mech, logR_obs, logR_mech, dR),   # choose what you want
    by = c("site", "Position")
  )


##split
set.seed(123)

n <- nrow(df_resid)
train_idx <- sample.int(n, floor(0.8 * n))

train_resid <- df_resid[train_idx, ]
test_resid  <- df_resid[-train_idx, ]

library(ranger)
##rf model
rf_fit <- ranger(
  dR ~ delGcat + lambda + stoichMet_donor +
    biomass  + npoc +
    clay + silt + fine + med + coarse,
  data = train_resid,
  num.trees = 1000,
  mtry = 4,
  min.node.size = 5,
  importance = "impurity"
)

##reconstruct KGML-corrected rates
test_resid$dR_hat  <- predict(rf_fit, data = test_resid)$predictions #RF model to capture addtional predictors
test_resid$logR_pred <- test_resid$logR_mech + test_resid$dR_hat #KGML prediction

test_resid$R_pred      <- exp(test_resid$logR_pred)    # KGML prediction
test_resid$R_mech_raw  <- exp(test_resid$logR_mech)    # mechanistic only
test_resid$R_obs       <- exp(test_resid$logR_obs)     # observed

##stats
rmse <- function(truth, estimate) {
  sqrt(mean((truth - estimate)^2, na.rm = TRUE))
}

rsq <- function(truth, estimate) {
  1 - sum((truth - estimate)^2) / sum((truth - mean(truth))^2)
}

rmse_mech <- rmse(test_resid$R_obs, test_resid$R_mech_raw)
rmse_kgml <- rmse(test_resid$R_obs, test_resid$R_pred)

rsq_mech <- rsq(test_resid$R_obs, test_resid$R_mech_raw)
rsq_kgml <- rsq(test_resid$R_obs, test_resid$R_pred)

rmse_mech
rmse_kgml
rsq_mech
rsq_kgml


##visualize

library(ggplot2)

p_mech <- ggplot(test_resid, aes(x = R_obs, y = R_mech_raw)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + ylim(0,2)+
  labs(x = "Observed R", y = "Mechanistic R_mech",
       title = "Mechanistic model") +
  theme_pubr(border=TRUE)

p_kgml <- ggplot(test_resid, aes(x = R_obs, y = R_pred)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,2)+
  labs(x = "Observed R", y = "KGML-corrected R_pred",
       title = "Mechanistic + KGML residual") +
  theme_pubr(border=TRUE)

# side by side
library(patchwork)  # install.packages("patchwork") once
plot1<-p_mech + p_kgml

pdf("KGML1_medianVh.pdf", width=6.5, height=3.5)
plot1
dev.off() 

##residual distribution

df_res_plot <- data.frame(
  residual = c(test_resid$dR, test_resid$dR - test_resid$dR_hat),
  model    = factor(rep(c("Mechanistic residual dR",
                          "KGML-corrected residual"),
                        each = nrow(test_resid)))
)

ggplot(df_res_plot, aes(x = residual, fill = model)) +
  geom_density(alpha = 0.4) +
  labs(x = "Residual (log space)", y = "Density",
       title = "Residual distribution: mechanistic vs KGML") +
  theme_pubr(border=TRUE)

##residual vs key predictors
test_resid$mech_resid_log  <- test_resid$dR
test_resid$kgml_resid_log  <- test_resid$dR - test_resid$dR_hat

plot2<-ggplot(test_resid, aes(x = 1/npoc)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(y = mech_resid_log, colour = "Mechanistic"), alpha = 0.7) +
  geom_point(aes(y = kgml_resid_log, colour = "KGML"), alpha = 0.7) +
  labs(x = "1/NPOC", y = "Residual (logR)") +
  scale_colour_manual(values = c("Mechanistic" = "#542788", "KGML" = "#b35806")) +
 theme_pubr(border=TRUE)+theme(legend.position = "right") 

pdf("KGML1_medianVh_residual.pdf", width=4.5, height=3)
plot2
dev.off() 

##variable importance
vi <- sort(rf_fit$variable.importance, decreasing = TRUE)
vi_df <- data.frame(
  variable = factor(names(vi), levels = names(vi)),
  importance = as.numeric(vi)
)

plot3<-ggplot(vi_df, aes(x = variable, y = importance)) +
  geom_col() +
  coord_flip() +
  labs(x = "Predictor", y = "Importance",
       title = "Random forest variable importance for dR") +
  theme_pubr(border=TRUE)

pdf("KGML1_medianVh_importance.pdf", width=4.5, height=3)
plot3
dev.off() 



##partial dependence plot
top_var <- "npoc"

# grid over npoc within observed range
npoc_grid <- seq(
  quantile(train_resid$npoc, 0.05, na.rm = TRUE),
  quantile(train_resid$npoc, 0.95, na.rm = TRUE),
  length.out = 50
)

# base data: median of other predictors
base_row <- as.data.frame(lapply(train_resid[, c("delGcat","lambda","ne",
                                                 "stoichMet_donor","biomass",
                                                 "ssa_tot","npoc",
                                                 "clay","silt","fine","med",
                                                 "coarse","d50_mm")],
                                 median, na.rm = TRUE))

pd_dat <- do.call(rbind, lapply(npoc_grid, function(x) {
  row <- base_row
  row$npoc <- x
  row
}))

dR_hat_grid <- predict(rf_fit, data = pd_dat)$predictions

pd_plot <- data.frame(
  npoc = npoc_grid,
  dR_hat = dR_hat_grid
)

ggplot(pd_plot, aes(x = npoc, y = dR_hat)) +
  geom_line() +
  labs(x = "npoc", y = "Predicted residual dR_hat",
       title = "Partial dependence of dR_hat on npoc") +
  theme_bw()



```


###setting baseline predictions with scalable Vh
```{r newVh}

##get a reference SSA value
SSA_ref <- median(df_resid$ssa_tot[df_resid$ssa_tot > 0], na.rm = TRUE)
SSA_ref

##get a scaling factor
df_fit <- df_resid[df_resid$ssa_tot > 0 & is.finite(df_resid$dR), ]

df_fit$log_ssa_ratio <- log(df_fit$ssa_tot / SSA_ref)

fit_ssa <- lm(dR ~ log_ssa_ratio, data = df_fit)
summary(fit_ssa)

alpha_ssa <- coef(fit_ssa)[["log_ssa_ratio"]]
alpha_ssa

##building new rates
df_kgml_ssa <- df_Vh %>%
  mutate(
    Vh0     = Vh0,  # keep for reference
    SSA_ref = SSA_ref,
    alpha_ssa = alpha_ssa,
    Vh_ssa = Vh0 * (ssa_tot / SSA_ref)^alpha_ssa,
    mu_max = 1,
    R_mech = mu_max * exp(-abs(stoichMet_donor) / (Vh_ssa * npoc)) * biomass,
    logR_obs  = log10(respC),
    logR_mech = log10(R_mech),
    dR        = logR_obs - logR_mech
  )





##visualize
plot1<-ggplot(df_kgml_ssa)+geom_point(aes(x=respC, y=dR))

cor(df_kgml_ssa$logR_obs, df_kgml_ssa$logR_mech, use = "complete.obs")    ##0.47


library(yardstick)

df_kgml_ssa %>%
  metrics(truth = respC, estimate = R_mech)


###prep new data set

df_test<-df_processed %>%
  dplyr::select(site, Position, delGcat_mean, lambda_mean,ne_mean, stoichMet_donor_mean, biomass_mean, ssa_tot_mean, respC_mean, npoc_mean,clay_mean, silt_mean, fine_mean, med_mean, coarse_mean, d50_mm) %>%
  rename_with(~gsub("_mean$","", .x))

df_resid<- df_test %>%
  dplyr::left_join(
    df_kgml_ssa %>% 
      dplyr::select(site, Position, Vh0, R_mech, logR_obs, logR_mech, dR),   # choose what you want
    by = c("site", "Position")
  )





##split
set.seed(123)

n <- nrow(df_resid)
train_idx <- sample.int(n, floor(0.8 * n))

train_resid <- df_resid[train_idx, ]
test_resid  <- df_resid[-train_idx, ]

library(ranger)
##rf model
rf_fit <- ranger(
  dR ~ delGcat + lambda + stoichMet_donor +
    biomass  + npoc +
    clay + silt + fine + med + coarse,
  data = train_resid,
  num.trees = 1000,
  mtry = 4,
  min.node.size = 5,
  importance = "impurity"
)

##reconstruct KGML-corrected rates
test_resid$dR_hat  <- predict(rf_fit, data = test_resid)$predictions #RF model to capture addtional predictors
test_resid$logR_pred <- test_resid$logR_mech + test_resid$dR_hat #KGML prediction

test_resid$R_pred      <- exp(test_resid$logR_pred)    # KGML prediction
test_resid$R_mech_raw  <- exp(test_resid$logR_mech)    # mechanistic only
test_resid$R_obs       <- exp(test_resid$logR_obs)     # observed

##stats
rmse <- function(truth, estimate) {
  sqrt(mean((truth - estimate)^2, na.rm = TRUE))
}

rsq <- function(truth, estimate) {
  1 - sum((truth - estimate)^2) / sum((truth - mean(truth))^2)
}

rmse_mech <- rmse(test_resid$R_obs, test_resid$R_mech_raw)
rmse_kgml <- rmse(test_resid$R_obs, test_resid$R_pred)

rsq_mech <- rsq(test_resid$R_obs, test_resid$R_mech_raw)
rsq_kgml <- rsq(test_resid$R_obs, test_resid$R_pred)

rmse_mech
rmse_kgml
rsq_mech
rsq_kgml



p_mech <- ggplot(test_resid, aes(x = R_obs, y = R_mech_raw)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + ylim(0,2)+
  labs(x = "Observed R", y = "Mechanistic R_mech",
       title = "Mechanistic model") +
  theme_pubr(border=TRUE)

p_kgml <- ggplot(test_resid, aes(x = R_obs, y = R_pred)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,2)+
  labs(x = "Observed R", y = "KGML-corrected R_pred",
       title = "Mechanistic + KGML residual") +
  theme_pubr(border=TRUE)

# side by side
library(patchwork)  # install.packages("patchwork") once
plot1<-p_mech + p_kgml

pdf("KGML2_medianVh.pdf", width=6.5, height=3.5)
plot1
dev.off() 


##residual distribution

df_res_plot <- data.frame(
  residual = c(test_resid$dR, test_resid$dR - test_resid$dR_hat),
  model    = factor(rep(c("Mechanistic residual dR",
                          "KGML-corrected residual"),
                        each = nrow(test_resid)))
)

ggplot(df_res_plot, aes(x = residual, fill = model)) +
  geom_density(alpha = 0.4) +
  labs(x = "Residual (log space)", y = "Density",
       title = "Residual distribution: mechanistic vs KGML") +
  theme_pubr(border=TRUE)

##residual vs key predictors
test_resid$mech_resid_log  <- test_resid$dR
test_resid$kgml_resid_log  <- test_resid$dR - test_resid$dR_hat

plot2<-ggplot(test_resid, aes(x = npoc)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(y = mech_resid_log, colour = "Mechanistic"), alpha = 0.6) +
  geom_point(aes(y = kgml_resid_log, colour = "KGML"), alpha = 0.6) +
  labs(x = "npoc", y = "Residual (logR)") +
  scale_colour_manual(values = c("Mechanistic" = "black", "KGML" = "red")) +
 theme_pubr(border=TRUE)+theme(legend.position = "right") 

pdf("KGML2_medianVh_residual.pdf", width=4.5, height=3)
plot2
dev.off() 


##variable importance
vi <- sort(rf_fit$variable.importance, decreasing = TRUE)
vi_df <- data.frame(
  variable = factor(names(vi), levels = names(vi)),
  importance = as.numeric(vi)
)

plot3<-ggplot(vi_df, aes(x = variable, y = importance)) +
  geom_col() +
  coord_flip() +
  labs(x = "Predictor", y = "Importance",
       title = "Random forest variable importance for dR") +
  theme_pubr(border=TRUE)

pdf("KGML2_medianVh_importance.pdf", width=4.5, height=3)
plot3
dev.off() 



```








###KGML3 log~log correlation

```{r newVh}

##get a reference SSA value
SSA_ref <- median(df_Vh$ssa_tot[df_Vh$ssa_tot > 0], na.rm = TRUE)
SSA_ref

##get a scaling factor
df_fit <- df_Vh[df_Vh$ssa_tot > 0, ]

df_fit$log_ssa_ratio <- log10(df_fit$ssa_tot/SSA_ref)

fit_inv <- lm(log10(Vh) ~ log10(ssa_tot), data = df_fit)
summary(fit_inv)

beta_inv <- coef(fit_inv)[["log10(ssa_tot)"]]
beta_inv

##building new rates
df_kgml_inv <- df_Vh %>%
  mutate(
    Vh0     = 0.05,  # keep for reference
    SSA_ref = SSA_ref,
    beta_inv=beta_inv,
    Vh_ssa_inv = Vh0 * (ssa_tot/SSA_ref)^beta_inv,
    mu_max = 1,
    R_mech = mu_max * exp(-abs(stoichMet_donor) / (Vh_ssa_inv * npoc)) * biomass,
    logR_obs  = log10(respC),
    logR_mech = log10(R_mech),
    dR        = logR_obs - logR_mech
  )



##visualize
plot1<-ggplot(df_kgml_inv)+geom_point(aes(x=respC, y=dR))

cor(df_kgml_inv$logR_obs, df_kgml_inv$logR_mech, use = "complete.obs")    ##0.47


###prep new data set

df_test<-df_processed %>%
  dplyr::select(site, Position, delGcat_mean, lambda_mean,ne_mean, stoichMet_donor_mean, biomass_mean, ssa_tot_mean, respC_mean, npoc_mean,clay_mean, silt_mean, fine_mean, med_mean, coarse_mean, d50_mm) %>%
  rename_with(~gsub("_mean$","", .x))

df_resid<- df_test %>%
  dplyr::left_join(
    df_kgml_inv %>% 
      dplyr::select(site, Position, Vh0, R_mech, logR_obs, logR_mech, dR),   # choose what you want
    by = c("site", "Position")
  )





##split
set.seed(123)

n <- nrow(df_resid)
train_idx <- sample.int(n, floor(0.8 * n))

train_resid <- df_resid[train_idx, ]
test_resid  <- df_resid[-train_idx, ]

library(ranger)
##rf model
rf_fit <- ranger(
  dR ~ delGcat + lambda + stoichMet_donor +
    biomass  + npoc +
    clay + silt + fine + med + coarse,
  data = train_resid,
  num.trees = 1000,
  mtry = 4,
  min.node.size = 5,
  importance = "impurity"
)

##reconstruct KGML-corrected rates
test_resid$dR_hat  <- predict(rf_fit, data = test_resid)$predictions #RF model to capture addtional predictors
test_resid$logR_pred <- test_resid$logR_mech + test_resid$dR_hat #KGML prediction

test_resid$R_pred      <- exp(test_resid$logR_pred)    # KGML prediction
test_resid$R_mech_raw  <- exp(test_resid$logR_mech)    # mechanistic only
test_resid$R_obs       <- exp(test_resid$logR_obs)     # observed

##stats
rmse <- function(truth, estimate) {
  sqrt(mean((truth - estimate)^2, na.rm = TRUE))
}

rsq <- function(truth, estimate) {
  1 - sum((truth - estimate)^2) / sum((truth - mean(truth))^2)
}

rmse_mech <- rmse(test_resid$R_obs, test_resid$R_mech_raw)
rmse_kgml <- rmse(test_resid$R_obs, test_resid$R_pred)

rsq_mech <- rsq(test_resid$R_obs, test_resid$R_mech_raw)
rsq_kgml <- rsq(test_resid$R_obs, test_resid$R_pred)

rmse_mech
rmse_kgml
rsq_mech
rsq_kgml



p_mech <- ggplot(test_resid, aes(x = R_obs, y = R_mech_raw)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + ylim(0,2)+
  labs(x = "Observed R", y = "Mechanistic R_mech",
       title = "Mechanistic model") +
  theme_pubr(border=TRUE)

p_kgml <- ggplot(test_resid, aes(x = R_obs, y = R_pred)) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,2)+
  labs(x = "Observed R", y = "KGML-corrected R_pred",
       title = "Mechanistic + KGML residual") +
  theme_pubr(border=TRUE)

# side by side
library(patchwork)  # install.packages("patchwork") once
plot1<-p_mech + p_kgml

pdf("KGML3_medianVh.pdf", width=6.5, height=3.5)
plot1
dev.off() 


##residual distribution

df_res_plot <- data.frame(
  residual = c(test_resid$dR, test_resid$dR - test_resid$dR_hat),
  model    = factor(rep(c("Mechanistic residual dR",
                          "KGML-corrected residual"),
                        each = nrow(test_resid)))
)

ggplot(df_res_plot, aes(x = residual, fill = model)) +
  geom_density(alpha = 0.4) +
  labs(x = "Residual (log space)", y = "Density",
       title = "Residual distribution: mechanistic vs KGML") +
  theme_pubr(border=TRUE)

##residual vs key predictors
test_resid$mech_resid_log  <- test_resid$dR
test_resid$kgml_resid_log  <- test_resid$dR - test_resid$dR_hat

plot2<-ggplot(test_resid, aes(x = 1/npoc)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(y = mech_resid_log, colour = "Mechanistic"), alpha = 0.7) +
  geom_point(aes(y = kgml_resid_log, colour = "KGML"), alpha = 0.7) +
  labs(x = "1/NPOC", y = "Residual (logR)") +
  scale_colour_manual(values = c("Mechanistic" = "#542788", "KGML" = "#b35806")) +
 theme_pubr(border=TRUE)+theme(legend.position = "right") 

pdf("KGML3_medianVh_residual.pdf", width=4.5, height=3)
plot2
dev.off() 


##variable importance
vi <- sort(rf_fit$variable.importance, decreasing = TRUE)
vi_df <- data.frame(
  variable = factor(names(vi), levels = names(vi)),
  importance = as.numeric(vi)
)

plot3<-ggplot(vi_df, aes(x = variable, y = importance)) +
  geom_col() +
  coord_flip() +
  labs(x = "Predictor", y = "Importance",
       title = "Random forest variable importance for dR") +
  theme_pubr(border=TRUE)

pdf("KGML2_medianVh_importance.pdf", width=4.5, height=3)
plot3
dev.off() 



```


###KGML to learn dependency on NPOC ========================================
```{r kgml}
##sete a fixed Vh value

Vh0 <- median(df_Vh$Vh, na.rm = TRUE)

##calculate mechanistic baseline+ resisual

df_kgml <- df_Vh %>%
  mutate(
    Vh0      = Vh0,                 # chosen baseline
    mu_max   = 1,              # your choice
    R_mech   = mu_max * exp(-abs(stoichMet_donor) / (Vh0 * npoc)) * biomass,
    logR_obs = log10(respC),
    logR_mech = log10(R_mech),
    dR       = logR_obs - logR_mech  # target for ML
  )



##visualize
plot1<-ggplot(df_kgml)+geom_point(aes(x=respC, y=dR))

cor(df_kgml$logR_obs, df_kgml$logR_mech, use = "complete.obs") ##0.53


###prep new data set

df_test<-df_processed %>%
  dplyr::select(site, Position, delGcat_mean, lambda_mean,ne_mean, stoichMet_donor_mean, biomass_mean, ssa_tot_mean, respC_mean, npoc_mean,clay_mean, silt_mean, fine_mean, med_mean, coarse_mean, d50_mm) %>%
  rename_with(~gsub("_mean$","", .x))

df_resid<- df_test %>%
  dplyr::left_join(
    df_kgml %>% 
      dplyr::select(site, Position, Vh0, R_mech, logR_obs, logR_mech, dR),   # choose what you want
    by = c("site", "Position")
  )


df_kgml_npoc<-df_resid%>%
  mutate(
    inv_npoc = 1 / npoc,
    log_npoc = log10(npoc)
  )


library(ranger)

rf_npc <- ranger(
  formula = dR ~ npoc + inv_npoc + log_npoc,
  data = df_kgml_npoc,
  importance = "permutation",
  num.trees = 500,
  min.node.size = 5,
  seed = 7
)

##apply KGML correction
df_kgml_npoc$npc_correction <- predict(rf_npc, data = df_kgml_npoc)$predictions

df_kgml_npoc <- df_kgml_npoc %>%
  mutate(
    logR_hybrid = logR_mech + npc_correction,
    dR_hybrid   = logR_obs - logR_hybrid
  )



kgml_stats_log <- df_kgml_npoc %>%
  metrics(truth = logR_obs, estimate = logR_hybrid)

kgml_stats_log


ggplot(df_kgml_npoc, aes(x = 1/npoc, y = dR)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess") +
  labs(x = "1/NPOC", y = "Residual (baseline)")


ggplot(df_kgml_npoc, aes(x = 1/npoc, y = dR_hybrid)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess") +
  labs(x = "1/NPOC", y = "Residual (KGML corrected)")

##plot
plot_npoc <- ggplot(df_kgml_npoc, aes(x = 1/npoc)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  
  # mechanistic residuals
  geom_point(aes(y = dR, colour = "Mechanistic"), alpha = 0.7) +
  
  # KGML(NPOC)-corrected residuals
  geom_point(aes(y = dR_hybrid, colour = "KGML"), alpha = 0.7) +
  
  scale_colour_manual(values = c(
    "Mechanistic" = "#542788",   # purple
    "KGML"        = "#b35806"    # orange
  )) +
  
  labs(x = "1/NPOC", y = "Residual (logR)", colour = "colour") +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

plot_npoc




pdf("KGML_npoc_residual.pdf", width=4.5, height=3)
plot_npoc
dev.off() 




```


###KGML to learn contributions of FTICR features================================================

```{r kgml}

ft<-read.csv("fticr_features.csv" ,colClasses=c("site"="character"))
df_merge <- df_Vh %>%
  inner_join(ft, by = c("site", "Position"))


##sete a fixed Vh value

Vh0 <- median(df_Vh$Vh, na.rm = TRUE)

##calculate mechanistic baseline+ resisual

df_kgml <- df_Vh %>%
  mutate(
    Vh0      = Vh0,                 # chosen baseline
    mu_max   = 1,              # your choice
    R_mech   = mu_max * exp(-abs(stoichMet_donor) / (Vh0 * npoc)) * biomass,
    logR_obs = log10(respC),
    logR_mech = log10(R_mech),
    dR       = logR_obs - logR_mech  # target for ML
  )



##visualize
plot1<-ggplot(df_kgml)+geom_point(aes(x=respC, y=dR))

cor(df_kgml$logR_obs, df_kgml$logR_mech, use = "complete.obs") ##0.53


###prep new data set
ft<-ft %>%
  dplyr::select(-npoc, -biomass, -ssa_tot, -clay, -silt, -fine, -med, -coarse)


df_resid<- ft %>%
  dplyr::left_join(
    df_kgml %>% 
      dplyr::select(site, Position, Vh0, R_mech, logR_obs, logR_mech, dR),   # choose what you want
    by = c("site", "Position")
  )
###remove rows not included in df_Vh dataframe
df_ml <- df_resid %>% filter(!is.na(dR))

##remove identifiers and non-feature variables
feature_cols <- setdiff(
  names(df_resid),
  c("site", "Position", 
    "logR_obs", "logR_mech", "R_mech", "Vh0", "dR")
)


library(ranger)

set.seed(7)

rf_fticr <- ranger(
  formula = reformulate(feature_cols, response = "dR"),
  data = df_ml,
  importance = "permutation",
  num.trees = 500,
  min.node.size = 5
)


##apply KGML correction
df_ml$kgml_correction <- predict(rf_fticr, data = df_ml)$predictions

df_ml <- df_ml %>%
  mutate(
    logR_hybrid = logR_mech + kgml_correction,
    dR_hybrid   = logR_obs - logR_hybrid
  )



kgml_stats_log <- df_ml %>%
  metrics(truth = logR_obs, estimate = logR_hybrid)

kgml_stats_log



####Feature importance ranking========================
library(ggplot2)
library(dplyr)

var_imp_df <- data.frame(
  feature = names(rf_fticr$variable.importance),
  importance = rf_fticr$variable.importance
) %>%
  arrange(desc(importance))

plot_feature<-ggplot(var_imp_df, aes(x = reorder(feature, importance), y = importance)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Permutation Importance (Random Forest)",
    x = "Feature",
    y = "Importance"
  ) +
  theme_minimal(base_size = 14)


pdf("KGML_fticr_importance.pdf", width=6, height=6)
plot_feature
dev.off() 


####
df_npoc <- df_Vh %>%
  dplyr::select(site, Position, inv_npoc)


df_ml <- df_ml %>%
  left_join(df_npoc, by = c("site", "Position"))



ggplot(df_ml, aes(x = inv_npoc, y = dR)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess") +
  labs(x = "1/NPOC", y = "Residual (baseline)")


ggplot(df_ml, aes(x = inv_npoc, y = dR_hybrid)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess") +
  labs(x = "1/NPOC", y = "Residual (KGML corrected)")

##plot
plot_npoc <- ggplot(df_ml, aes(x = inv_npoc)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  
  # mechanistic residuals
  geom_point(aes(y = dR, colour = "Mechanistic"), alpha = 0.7) +
  
  # KGML(NPOC)-corrected residuals
  geom_point(aes(y = dR_hybrid, colour = "KGML"), alpha = 0.7) +
  
  scale_colour_manual(values = c(
    "Mechanistic" = "#542788",   # purple
    "KGML"        = "#b35806"    # orange
  )) +
  
  labs(x = "1/NPOC", y = "Residual (logR)", colour = "colour") +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

plot_npoc




pdf("KGML_fticr_residual.pdf", width=4.5, height=3)
plot_npoc
dev.off() 




```


##data-driven approach=============================================================
###RF model
```{r RFmodel}

ft<-read.csv("fticr_features.csv" ,colClasses=c("site"="character"))

##Data split
data_split <- initial_split(ft, prop = 0.8)
train_data <- training(data_split)
test_data  <- testing(data_split)

library(tidymodels)
set.seed(123)

rf_model <- rand_forest(
  trees = 1000,
  mtry  = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_recipe <- recipe(respC ~ ., data = train_data) %>%
  update_role(site, new_role = "id") %>%   # do not use as predictor
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())


rf_wf <- workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_recipe)

rf_grid <- grid_regular(
  mtry(range = c(5, 40)),
  min_n(range = c(2, 20)),
  levels = 5
)

rf_tuned <- tune_grid(
  rf_wf,
  resamples = vfold_cv(train_data, v = 5),
  grid = rf_grid,
  metrics = metric_set(yardstick::rmse),   # <-- FIX
  control = control_grid(save_pred = TRUE)
)


rf_best <- select_best(rf_tuned, metric= "rmse")

rf_final <- finalize_workflow(rf_wf, rf_best)

rf_fit <- rf_final %>% fit(train_data)

rf_pred <- predict(rf_fit, test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred)

rf_metrics <- rf_pred %>%
  metrics(truth = respC, estimate = respC_pred)

rf_metrics

###plots (predictions and residuals)======
rf_train_pred <- predict(rf_fit, train_data) %>%
  bind_cols(train_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(
    resid_raw = respC - respC_pred,
    resid_ratio = (respC + 1e-6) / (respC_pred + 1e-6),
    resid_log = log(resid_ratio),
    inv_npoc = 1 / npoc,
    dataset = "train"
  )

rf_test_pred <- predict(rf_fit, test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(
    resid_raw = respC - respC_pred,
    resid_ratio = (respC + 1e-6) / (respC_pred + 1e-6),
    resid_log = log(resid_ratio),
    inv_npoc = 1 / npoc,
    dataset = "test"
  )

rf_all_pred <- bind_rows(rf_train_pred, rf_test_pred)




p1 <- ggplot(rf_all_pred, aes(x = inv_npoc, y = resid_log, color = dataset)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=c( "train" = "#542788",   # purple
    "test"  = "#b35806"))+    # orange
  labs(
    x = "1 / NPOC",
    y = "log(Observed / Predicted)"
  )+  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("RF_fticr_residual.pdf", width=4.2, height=3)
p1
dev.off() 


p2<-ggplot(rf_all_pred, aes(
    x = respC,
    y = respC_pred,
    color = dataset
  )) +
  geom_point(alpha = 0.6) +
  scale_color_manual(values = c(
    "train" = "#542788",   # purple
    "test"  = "#b35806"    # orange
  )) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,0.5)+
  labs(
    x = "Observed respC",
    y = "Predicted respC"
  )+  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("RF_fticr_fit.pdf", width=4.2, height=3)
p2
dev.off() 



library(vip)

p3<-rf_fit %>%
  extract_fit_engine() %>%
  vip(num_features = 40, bar = TRUE) +
  labs(title = "Feature Importances (RF)")

pdf("RF_fticr_feature.pdf", width=6, height=6)
p3
dev.off() 
```



###RF model with reduced FTICR data features
```{r RFmodel}

ft<-read.csv("fticr_features.csv" ,colClasses=c("site"="character"))

fticr_cols <- c(
  "n_peaks","shannon",
  "NOSC_med","NOSC_iqr","NOSC_mean","NOSC_p10","NOSC_p90","NOSC_range90",
  "DBE_med","DBE_mean","DBE_iqr",
  "AI_med","AI_iqr",
  "delG_med","delG_iqr",
  "lambda_med","lambda_iqr",
  "Cnum_med","Cnum_iqr",
  "frac_NOSC_pos","frac_NOSC_low","frac_AI_high","DBE_C_ratio_mean",
  "frac_ConHC","frac_Lipid","frac_AminoSugar","frac_Protein","frac_Tannin",
  "frac_UnsatHC","frac_Lignin","frac_Carb","frac_Other",
  "ratio_Protein_Lignin","ratio_Lipid_Carb","ratio_UnsatHC_ConHC"
)

library(caret)

corr_mat <- cor(ft[ , fticr_cols], use = "pairwise.complete.obs")
high_corr <- findCorrelation(corr_mat, cutoff = 0.80)
fticr_reduced <- fticr_cols[-high_corr]
fticr_reduced

##build new trainign dataset using reduced FTICR features
rf_train_reduced <- ft %>%
  select(site, Position, npoc, biomass, respC, ssa_tot, 
         clay, silt, fine, med, coarse,
         all_of(fticr_reduced))


##Data split
data_split <- initial_split(rf_train_reduced, prop = 0.8)
train_data <- training(data_split)
test_data  <- testing(data_split)

library(tidymodels)
set.seed(123)

rf_model <- rand_forest(
  trees = 1000,
  mtry  = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_recipe <- recipe(respC ~ ., data = train_data) %>%
  update_role(site, new_role = "id") %>%   # do not use as predictor
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())


rf_wf <- workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_recipe)

rf_grid <- grid_regular(
  mtry(range = c(5, 40)),
  min_n(range = c(2, 20)),
  levels = 5
)

rf_tuned <- tune_grid(
  rf_wf,
  resamples = vfold_cv(train_data, v = 5),
  grid = rf_grid,
  metrics = metric_set(yardstick::rmse),   # <-- FIX
  control = control_grid(save_pred = TRUE)
)


rf_best <- select_best(rf_tuned, metric= "rmse")

rf_final <- finalize_workflow(rf_wf, rf_best)

rf_fit <- rf_final %>% fit(train_data)

rf_pred <- predict(rf_fit, test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred)

rf_metrics <- rf_pred %>%
  metrics(truth = respC, estimate = respC_pred)

rf_metrics

###plots (predictions and residuals)======
rf_train_pred <- predict(rf_fit, train_data) %>%
  bind_cols(train_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(
    resid_raw = respC - respC_pred,
    resid_ratio = (respC + 1e-6) / (respC_pred + 1e-6),
    resid_log = log(resid_ratio),
    inv_npoc = 1 / npoc,
    dataset = "train"
  )

rf_test_pred <- predict(rf_fit, test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(
    resid_raw = respC - respC_pred,
    resid_ratio = (respC + 1e-6) / (respC_pred + 1e-6),
    resid_log = log(resid_ratio),
    inv_npoc = 1 / npoc,
    dataset = "test"
  )

rf_all_pred <- bind_rows(rf_train_pred, rf_test_pred)




p1 <- ggplot(rf_all_pred, aes(x = inv_npoc, y = resid_log, color = dataset)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=c( "train" = "#542788",   # purple
    "test"  = "#b35806"))+    # orange
  labs(
    x = "1 / NPOC",
    y = "log(Observed / Predicted)"
  )+  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("RF_fticr_residual_new.pdf", width=4.2, height=3)
p1
dev.off() 


p2<-ggplot(rf_all_pred, aes(
    x = respC,
    y = respC_pred,
    color = dataset
  )) +
  geom_point(alpha = 0.6) +
  scale_color_manual(values = c(
    "train" = "#542788",   # purple
    "test"  = "#b35806"    # orange
  )) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,0.5)+
  labs(
    x = "Observed respC",
    y = "Predicted respC"
  )+  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("RF_fticr_fit_new.pdf", width=4.2, height=3)
p2
dev.off() 


###
rf_imp <- rf_fit %>% 
  workflows::extract_fit_engine() %>%
  { tibble(
       variable = names(.$variable.importance),
       importance = unname(.$variable.importance)
     ) }

top_n <- 20   # change to any number you want

rf_imp_top <- rf_imp %>%
  arrange(desc(importance)) %>%
  slice(1:top_n)

p_rf <- ggplot(rf_imp_top,
               aes(x = reorder(variable, importance),
                   y = importance)) +
  geom_col(fill = "#8073ac") +               # same color as NN plot
  coord_flip() +
  labs(
    title = "Random Forest Predictor Importance",
    x = "Predictor",
    y = "Importance"
  ) +
  theme_pubr(border = TRUE) +
  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 20))

pdf("RF_Importance_new.pdf", width=5, height=8)
p_rf
dev.off() 

```




### Neural networks
```{R NN}

##prepare data
ft<-read.csv("fticr_features.csv" ,colClasses=c("site"="character"))
ft_clean<-ft %>%
  select(-site, -Position)

###NN
library(tidymodels)
library(keras)
library(vip)
library(yardstick)


set.seed(123)

# Split data
data_split <- initial_split(ft_clean, prop = 0.8, strata = respC)
train_data  <- training(data_split)
test_data   <- testing(data_split)

nn_recipe <- recipe(respC ~ ., data = train_data) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())        # predictors only


# Model
nn_model <- mlp(
    hidden_units = tune(),
    penalty = tune(),
    epochs = tune()
  ) %>%
  set_engine("keras") %>%
  set_mode("regression")

# Grid
nn_grid <- grid_space_filling(
  hidden_units(range = c(16, 64)),
  penalty(range = c(-5, -2)),
  epochs(range = c(30, 80)),
  size = 8
)

# Workflow
nn_wf <- workflow() %>%
  add_model(nn_model) %>%
  add_recipe(nn_recipe)

# CV
cv_folds <- vfold_cv(train_data, v = 3, strata = respC)

nn_tuned <- tune_grid(
  nn_wf,
  resamples = cv_folds,
  grid = nn_grid,
  metrics = metric_set(yardstick::rmse),
  control = control_grid(save_pred = TRUE)
)

# Best params
best_params <- select_best(nn_tuned, metric = "rmse")

# Finalize
final_nn <- finalize_workflow(nn_wf, best_params)

# Fit the final model on the full training data
final_fit <- final_nn %>%
  fit(train_data)

# Predict on test set
test_pred <- final_fit %>%
  predict(test_data) %>%
  bind_cols(test_data) 

# Test metrics (original scale)
test_pred <- final_fit %>%
  predict(test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred)





####plots

# Training predictions
train_pred <- final_fit %>%
  predict(train_data) %>%
  bind_cols(train_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(dataset = "Training")

# Testing predictions
test_pred <- final_fit %>%
  predict(test_data) %>%
  bind_cols(test_data) %>%
  dplyr::rename(respC_pred = .pred) %>%
  mutate(dataset = "Testing")

# Combine
all_pred <- bind_rows(train_pred, test_pred)

library(yardstick)

nn_stats <- all_pred %>%
  metrics(truth = respC, estimate = respC_pred)

nn_stats



eps <- 1e-8

all_pred <- all_pred %>%
  mutate(
    respC_clamped = pmax(respC, eps),
    respC_pred_clamped = pmax(respC_pred, eps),
    resid_log = log(respC_clamped / respC_pred_clamped)
  )

###

p1 <- ggplot(all_pred, aes(x = 1/npoc, y = resid_log, color = dataset)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values = c(
    "Training" = "#542788",
    "Testing"  = "#b35806"
  )) +
  labs(
    x = "1 / NPOC",
    y = "log(Observed / Predicted)"
  ) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("NN_fticr_residual_new.pdf", width=4.2, height=3)
p1
dev.off() 




p2 <- ggplot(all_pred, aes(
    x = respC,
    y = respC_pred,
    color = dataset
  )) +
  geom_point(alpha = 0.6) +
  scale_color_manual(values = c(
    "Training" = "#542788",
    "Testing"  = "#b35806"
  )) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +ylim(0,0.6)+
  labs(
    x = "Observed respC",
    y = "Predicted respC"
  ) +
  theme_pubr(border = TRUE) +
  theme(legend.position = "right")

pdf("NN_fticr_corr_new.pdf", width=4.2, height=3)
p2
dev.off() 


library(tidymodels)
library(DALEX)
library(ggplot2)

nn_fit_only <- workflows::extract_fit_engine(final_fit)

trained_rec <- workflows::extract_recipe(final_fit, estimated = TRUE)

train_processed <- bake(trained_rec, new_data = train_data)

X <- train_processed %>% dplyr::select(-respC)
y <- train_processed$respC

nn_predict <- function(model, newdata) {
  as.numeric(predict(model, as.matrix(newdata)))
}

baseline_pred <- nn_predict(nn_fit_only, X)
baseline_rmse <- yardstick::rmse_vec(y, baseline_pred)

perm_importance <- function(model, X, y, baseline_rmse) {
  
  vars <- colnames(X)
  results <- numeric(length(vars))
  
  for (i in seq_along(vars)) {
    X_perm <- X
    X_perm[[vars[i]]] <- sample(X_perm[[vars[i]]])
    
    pred_perm <- nn_predict(model, X_perm)
    results[i] <- yardstick::rmse_vec(y, pred_perm) - baseline_rmse
  }
  
  tibble(variable = vars, dropout_rmse = results)
}

vi_nn <- perm_importance(nn_fit_only, X, y, baseline_rmse)

#
top_n <- 20   # choose any number you like

vi_top <- vi_nn %>%
  arrange(desc(dropout_rmse)) %>%
  slice(1:top_n)


p3<-ggplot(vi_top %>% arrange(desc(dropout_rmse)),
       aes(x = reorder(variable, dropout_rmse), y = dropout_rmse)) +
  geom_col(fill = "#8073ac") +
  coord_flip() +
  labs(
    title = "NN Predictor Importance",
    x = "Predictor",
    y = "Increase in RMSE when permuted"
  ) +
  theme_pubr(border = TRUE)

pdf("NN_Importance_new.pdf", width=5, height=8)
p3
dev.off() 

```



